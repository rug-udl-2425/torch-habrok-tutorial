{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Deep Learning 2024-25 - Introduction to PyTorch\n",
    "\n",
    "PyTorch is a popular framework for Machine Learning, particularly suitable for **Deep Learning**.\n",
    "It offers an extensive support for tensor computation with support for GPU acceleration and automatic differentiation.\n",
    "Nowadays it is the de-facto choice for most researchers due to its ease of use and code readability.\n",
    "\n",
    "In this tutorial, we are going to cover the basics of PyTorch for Python, including:\n",
    "- Tensors and images\n",
    "- Operations\n",
    "- Automatic differentiation (_autograd_)\n",
    "- Building and training Neural Networks\n",
    "  - Transfer learning\n",
    "  - Training on custom datasets\n",
    "- Saving and loading models\n",
    "- Using GPU\n",
    "\n",
    "we will then transition to Habrok.\n",
    "Ivaylo will explain how the RUG HPC cluster works and how we can use its functionalities to train our models on the cluster.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install PyTorch, refer to the installation guide on the official website: https://pytorch.org/get-started/locally/.\n",
    "We strongly suggest you do so in a virtual (conda) environment.\n",
    "\n",
    "In addition, to reproduce the results of this tutorial, you will need the following libraries:\n",
    "\n",
    "- NumPy\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Tensor\n",
    "\n",
    "At the very basics of PyTorch lies the Tensor, an object-oriented implementation of the multidimensional array.\n",
    "Tensors are the building blocks of PyTorch, and they are used to store data and perform operations on it.\n",
    "\n",
    "Despite being very similar in functionality to NumPy arrays, PyTorch tensors have some differences.\n",
    "\n",
    "For instance, a PyTorch tensor will always default to a float32 tensor, regardless of the input data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n",
      "Data type: torch.float32\n",
      "------------\n",
      "[1 2 3 4 5]\n",
      "Data type: int64\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3,4,5])\n",
    "y = np.array([1,2,3,4,5])\n",
    "print(x)\n",
    "print(\"Data type:\", x.dtype)\n",
    "print(\"------------\")\n",
    "print(y)\n",
    "print(\"Data type:\", y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have a shape which we can access with the `shape` attribute or the `size` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5]), 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, additionally, access the number of dimensions with the `dim` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors support an arbitrary number of dimensions:\n",
    "\n",
    "![](img/tensors.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D (matrix)\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "----------------\n",
      "3D\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "torch.Size([2, 2, 3])\n",
      "----------------\n",
      "4D\n",
      "tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]])\n",
      "torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"2D (matrix)\")\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(\"----------------\")\n",
    "print(\"3D\")\n",
    "x = torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(\"----------------\")\n",
    "print(\"4D\")\n",
    "x = torch.tensor([[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add dimensions to a tensor using the `unsqueeze` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) \n",
      " Shape: torch.Size([4]) \n",
      "\n",
      "x.unsqueeze(0) turns x into a row vector\n",
      "tensor([[1, 2, 3, 4]]) \n",
      " Shape: torch.Size([1, 4]) \n",
      "\n",
      "Turn x into a column vector:\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4])\n",
    "print(x, \"\\n\", f\"Shape: {x.shape}\", \"\\n\")\n",
    "\n",
    "y = x.unsqueeze(dim=0)\n",
    "print(\"x.unsqueeze(0) turns x into a row vector\")\n",
    "print(y, \"\\n\", f\"Shape: {y.shape}\", \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Turn x into a column vector:\")\n",
    "# how can we turn x into a column vector?\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several ways of constructing tensors, similarly to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416]])\n",
      "tensor([ 0,  2,  4,  6,  8, 10])\n",
      "tensor([ 0.,  2.,  4.,  6.,  8., 10.])\n",
      "tensor([[0.3946, 0.7115, 0.1050],\n",
      "        [0.6489, 0.0580, 0.9146]])\n",
      "tensor([[ 1.9106,  1.0927, -1.3233],\n",
      "        [-0.7983, -0.1926,  0.5385]])\n",
      "tensor([[ 1.7109,  2.5262, -0.2447],\n",
      "        [10.7194, 14.5181, -3.7983]])\n",
      "tensor([[0., 1., 1.],\n",
      "        [1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor of zeros or ones\n",
    "print(torch.zeros(2, 3))\n",
    "print(torch.ones(2, 3))\n",
    "\n",
    "# Create constant tensor\n",
    "print(torch.full((2, 3), torch.pi))\n",
    "\n",
    "# Create sequence tensor\n",
    "print(torch.arange(0, 12, 2))\n",
    "\n",
    "# Create sequence tensor with fixed number of elements\n",
    "print(torch.linspace(0, 10, 6))\n",
    "\n",
    "# Create tensor as sample from Uniform(0,1)\n",
    "print(torch.rand(2, 3))\n",
    "\n",
    "# Create tensor as sample from Normal(0,1)\n",
    "print(torch.randn(2, 3))\n",
    "\n",
    "# Create tensor as sample from Normal(2,5)\n",
    "print(torch.normal(mean=2, std=5, size=(2, 3)))\n",
    "\n",
    "# Create tensor as sample from Bernoulli(0.5)\n",
    "print(torch.bernoulli(torch.full((2, 3), 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reshape tensors, we can use the `reshape` method, specifying the destination dimensions.\n",
    "\n",
    "Let's take this example form before\n",
    "```python\n",
    "print(torch.arange(0, 12, 2))\n",
    "```\n",
    "\n",
    "How can we turn this tensor into a 2x3 tensor, like all the other tensor in the cell above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 12, 2)\n",
    "# reshape x into a 2x3 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `slice` tensors to extract a subset of the data.\n",
    "\n",
    "Slicing works similarly as in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x (shape torch.Size([4, 3, 2])):\n",
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [ 8,  9],\n",
      "         [10, 11]],\n",
      "\n",
      "        [[12, 13],\n",
      "         [14, 15],\n",
      "         [16, 17]],\n",
      "\n",
      "        [[18, 19],\n",
      "         [20, 21],\n",
      "         [22, 23]]]) \n",
      "\n",
      "Get only first matrix (x[0]):\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]]) \n",
      "\n",
      "Get only first row of first matrix (x[0,0]):\n",
      "tensor([0, 1]) \n",
      "\n",
      "Get only first element of first row of first matrix (x[0,0,0]):\n",
      "tensor(0) \n",
      "\n",
      "Get first two rows of second and third matirx of x (x[1:3,:2]):\n",
      "tensor([[[ 6,  7],\n",
      "         [ 8,  9]],\n",
      "\n",
      "        [[12, 13],\n",
      "         [14, 15]]]) \n",
      "\n",
      "Get first and third rows of second and third matirx of x (x[1:3,(0,2)]):\n",
      "tensor([[[ 6,  7],\n",
      "         [10, 11]],\n",
      "\n",
      "        [[12, 13],\n",
      "         [16, 17]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 24).reshape(4, 3, 2)\n",
    "\n",
    "print(f\"Original x (shape {x.shape}):\")\n",
    "print(x, \"\\n\")\n",
    "\n",
    "print(f\"Get only first matrix (x[0]):\")\n",
    "print(x[0], \"\\n\")\n",
    "\n",
    "print(f\"Get only first row of first matrix (x[0,0]):\")\n",
    "print(x[0,0], \"\\n\")\n",
    "\n",
    "print(f\"Get only first element of first row of first matrix (x[0,0,0]):\")\n",
    "print(x[0,0,0], \"\\n\")\n",
    "\n",
    "print(f\"Get first two rows of second and third matirx of x (x[1:3,:2]):\")\n",
    "print(x[1:3,:2], \"\\n\")\n",
    "\n",
    "print(f\"Get first and third rows of second and third matirx of x (x[1:3,(0,2)]):\")\n",
    "print(x[1:3,(0,2)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can use the `:` symbol in a given dimension to request all of the elements from a particular dimension.\n",
    "\n",
    "You can try solving this without using for loops:\n",
    "\n",
    "* Extract the first row of each matrix of `x`\n",
    "* Extract the first column of each matrix of `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this\n",
    "\n",
    "`Get only first element of first row of first matrix (x[0,0,0])`\n",
    "\n",
    "returns this\n",
    "\n",
    "`tensor(0)`.\n",
    "\n",
    "This is different from the NumPy behavior, where it would return a scalar.\n",
    "We can extract the scalar value of \"singleton tensors\" using the `item` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10) ; 10\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12, 2).reshape(2, 3)\n",
    "val = x[1, 2]\n",
    "print(val, \";\" ,val.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "\n",
    "Tensors support a wide range of linear algebra operations.\n",
    "\n",
    "The main thing we need to be careful is that the basic arithmetic operations (+, -, *, /, //, %) are **element-wise**.\n",
    "\n",
    "The multiplication `*` does not correspond to the scalar product, but to the Hadamard (element-wise) product.\n",
    "\n",
    "Be also careful to the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2,  4],\n",
      "        [ 6,  8, 10]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4, 12],\n",
       "        [24, 40, 60]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 12, 2).reshape(2, 3)\n",
    "y = torch.arange(1, 7).reshape(2, 3)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m \u001b[38;5;66;03m# this is not matrix multiplication!\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12, 2).reshape(2, 3)\n",
    "y = torch.arange(1, 7).reshape(3, 2)\n",
    "\n",
    "x * y # this is not matrix multiplication!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication can be performed using `@` or `matmul`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 26,  32],\n",
      "        [ 80, 104]])\n",
      "tensor([[ 26,  32],\n",
      "        [ 80, 104]])\n",
      "tensor([[ 26,  32],\n",
      "        [ 80, 104]])\n",
      "tensor([[ 26,  32],\n",
      "        [ 80, 104]])\n",
      "tensor([[ 0, 12],\n",
      "        [ 6, 32],\n",
      "        [20, 60]])\n"
     ]
    }
   ],
   "source": [
    "print(x @ y)\n",
    "\n",
    "print(x.matmul(y))\n",
    "\n",
    "print(x.mm(y))\n",
    "\n",
    "print(torch.matmul(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful also at vector multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "tensor(32.)\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3])\n",
    "y = torch.Tensor([4,5,6])\n",
    "\n",
    "print(x * y) # not a dot product\n",
    "print(torch.dot(x, y)) # dot product\n",
    "print(x @ y) # dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensional operations\n",
    "\n",
    "We can perform operations along a given dimension using the `dim` argument.\n",
    "\n",
    "Let's suppose we want to get the sum of all the rows of a matrix.\n",
    "\n",
    "We can use the `sum` method with the `dim` argument set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2,  4],\n",
      "        [ 6,  8, 10]])\n",
      "----------------\n",
      "Sum of rows of x\n",
      "tensor([ 6, 24])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12, 2).reshape(2, 3)\n",
    "print(x)\n",
    "print(\"----------------\")\n",
    "print(\"Sum of rows of x\")\n",
    "\n",
    "print(x.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x.sum(dim=1)` means: we iterate over the dimension 1 (rows) and sum all the elements for each iteration.\n",
    "\n",
    "The concept of dimensional operations can be applied to very common reduction operations, such as `mean`, `std`, `max`, `min`, and even the norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n",
      "----------------\n",
      "Norm of x\n",
      "tensor(14.8324)\n",
      "----------------\n",
      "Norm of x with p=1\n",
      "tensor(30.)\n",
      "----------------\n",
      "Matrix L1 norm\n",
      "tensor(14.)\n",
      "----------------\n",
      "L2 norm of every column\n",
      "tensor([ 6.0000,  8.2462, 10.7703])\n",
      "L2 norm of every row\n",
      "tensor([ 4.4721, 14.1421])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12, 2).reshape(2, 3).float()\n",
    "\n",
    "print(x)\n",
    "print(\"----------------\")\n",
    "\n",
    "print(\"Norm of x\")\n",
    "print(x.norm()) # defaults to frobenius norm\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Norm of x with p=1\")\n",
    "print(x.norm(p=1)) # Manhattan distance\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Matrix L1 norm\")\n",
    "print(torch.linalg.norm(x, ord=1))\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"L2 norm of every column\")\n",
    "print(x.norm(dim=0))\n",
    "print(\"L2 norm of every row\")\n",
    "print(x.norm(dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Consider the tensor `x` defined as `x = torch.arange(0, 24).reshape(3, 2, 4)`.\n",
    "This tensor can be used to represent an RGB image of dimension 2x4 pixels.\n",
    "\n",
    "![](img/rgb_image.png)\n",
    "\n",
    "Compute the per-channel mean of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* \n",
    "\n",
    "While images are normally stored as 3D tensors `(height, width, channels)`, PyTorch uses a different convention `(channels, height, width)`.\n",
    "\n",
    "You can transition between the two conventions using the `permute` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1458234257.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    img_torch = # your code here - recover img_torch from img_classic\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "img_torch = torch.arange(0, 24).reshape(3, 2, 4)\n",
    "\n",
    "img_classic = img_torch.permute(1, 2, 0) # shift first dimension to last\n",
    "\n",
    "img_torch = # your code here - recover img_torch from img_classic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
