{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a NN\n",
    "\n",
    "In this part of the tutrorial, we'll be training a simple MLP on MNIST.\n",
    "We'll go over the basic components for the training part:\n",
    "- Datasets\n",
    "- DataLoaders\n",
    "- The basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# tqdm adds support for progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# torchvision provides support for computer vision (datasets, transformations, models,...)\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# torcheval provides support for evaluation metrics\n",
    "from torcheval import metrics\n",
    "\n",
    "# timm is a HuggingFace library providing a large collection of pre-trained image models (>> torchvision)\n",
    "import timm\n",
    "\n",
    "# extra libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first download the MNIST dataset and then define the model and the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root=\"data\", train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets to be used in PyTorch should be subclasses of `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(mnist_train, torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` provides the basic interface to access the data and defines data augmentation/preprocessing steps:\n",
    "- the `transform` attribute provides the information about the preprocessing steps to be applied to the data\n",
    "- `__len__` should return the size of the dataset\n",
    "- `__getitem__` should return the item at the given index **after applying preprocessing**\n",
    "\n",
    "![](img/dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.transform is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the dataset essentially contains basic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = mnist_train[0]\n",
    "img = img.copy()\n",
    "\n",
    "img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x798851359ad0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some basic transformations to the dataset so it can be elaborated by the dataset:\n",
    "\n",
    "- `ToTensor` converts the image to a tensor and normalizes it in the 0-1 range. This is a **preprocessing step** since it's not deterministic. \n",
    "  - We can very well convert the whole dataset to tensors beforehand. **Question**: What prevents us from doing this?\n",
    "- `RandomAffine` applies a random affine transformation (rotation + translation + scaling) to the image. This is a **data augmentation step** since it's non-deterministic and we want to apply it on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomAffine(degrees=10, scale=(0.9, 1.1)),\n",
    "])\n",
    "\n",
    "mnist_train.transform = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Transformed')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAGgCAYAAAB47/I2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq3UlEQVR4nO3df5SVdZ0H8M/l18jgzE1SmCEQqVVTUTz5A2M1xGJyTHYBPWt6bCFbTxZYLKalbiv9EtfU0xrpup0iLTX3dMwoPCkbzFDHdNHQTMvFIyXmzHIkmUHUIeTZP1pmHUHkGe7Mne+9r9c5zznc536/9/t55rnej+955t5byLIsCwAAgIQNKncBAAAA+0qwAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAHiDQqGwV1tLS0u5S+3hZz/7WRx//PExYsSIKBQKcc8995S7pJJoaWkZkD9vBpYh5S4AAGCg+eUvf9nj9pe+9KVYtWpVrFy5ssf+I488sj/L2qMsy+Lv/u7v4rDDDotly5bFiBEj4vDDDy93WdBvBBsAgDc46aSTetw+6KCDYtCgQbvsf6OXX345amtr+7K0N/X888/Hn/70p5g1a1a8//3vL8ljvvLKK7HffvtFoVAoyeNBX/KnaAAAvXDqqafGxIkTY/Xq1TFlypSora2NCy64ICIi7rrrrmhqaorGxsYYPnx4HHHEEfG5z30utm7d2uMx5s6dG/vvv388/fTTccYZZ8T+++8f48aNi0suuSS6urp6jL355ptj0qRJsf/++0ddXV28+93vjiuuuCIiIhYtWhRjx46NiIjPfvazUSgU4pBDDume+4tf/CLe//73R11dXdTW1saUKVNi+fLlPR7/O9/5ThQKhbj//vvjggsuiIMOOihqa2ujq6ur+1h/+ctfxpQpU2L48OFxyCGHxNKlSyMiYvny5fGe97wnamtr4+ijj46f/vSnu/y81q1bF+edd16MGjUqampq4ogjjohvfOMbu4z73e9+F6effnrU1tbGgQceGBdddFFs2bIl59mhGrliAwDQS21tbXH++efHZZddFldffXUMGvSX3xmvW7cuzjjjjFiwYEGMGDEifve738W//Mu/xH/913/t8udsf/7zn+Nv/uZv4mMf+1hccsklsXr16vjSl74UxWIx/vmf/zkiIr7//e/HJz/5ybj44ovjuuuui0GDBsXTTz8dTz75ZERE/MM//ENMmjQpZs+eHRdffHGcd955UVNTExERra2tMX369DjmmGPiW9/6VtTU1MRNN90UM2bMiDvvvDPOOeecHvVccMEF8aEPfSi++93vxtatW2Po0KEREdHe3h4f/ehH47LLLouxY8fG17/+9bjgggtiw4YN8YMf/CCuuOKKKBaL8cUvfjFmzpwZzzzzTIwZMyYiIp588smYMmVKHHzwwXH99ddHQ0ND3HffffGpT30qXnjhhbjqqqsiIuJ//ud/YurUqTF06NC46aabYvTo0XH77bfH/Pnz++gMUlEyAAD2aM6cOdmIESN67Js6dWoWEdnPfvazPc7dsWNH9uc//zlrbW3NIiJ77LHHejxuRGT/8R//0WPOGWeckR1++OHdt+fPn5+97W1v2+M669evzyIi++pXv9pj/0knnZSNGjUq27JlS/e+7du3ZxMnTszGjh2b7dixI8uyLFu6dGkWEdnf//3f7/LYO4/14Ycf7t63adOmbPDgwdnw4cOzP/7xj937H3300SwishtvvLF73wc/+MFs7NixWUdHR4/HnT9/frbffvtlf/rTn7Isy7LPfvazWaFQyB599NEe46ZPn55FRLZq1ao9/gyobv4UDQCglw444IA47bTTdtn/zDPPxHnnnRcNDQ0xePDgGDp0aEydOjUiIn7729/2GFsoFGLGjBk99h1zzDHxhz/8ofv2iSeeGJs3b45zzz03fvSjH8ULL7ywV/Vt3bo1HnrooTj77LNj//33794/ePDg+MhHPhLPPfdcPPXUUz3mnHXWWbt9rMbGxjjuuOO6b48cOTJGjRoVxx57bPeVmYiII444IiKiu/5XX301fvazn8WsWbOitrY2tm/f3r2dccYZ8eqrr8aDDz4YERGrVq2Ko446KiZNmtRj7fPOO2+vjpfqJtgAAPRSY2PjLvteeumlOOWUU+Khhx6KL3/5y9HS0hJr1qyJu+++OyL+8ob816utrY399tuvx76ampp49dVXu29/5CMfiW9/+9vxhz/8Ic4666wYNWpUTJ48OVasWLHH+l588cXIsmy3de4MI5s2bXrLY4r4S5B5o2HDhu2yf9iwYRER3fVv2rQptm/fHl//+tdj6NChPbYzzjgjIqI7qG3atCkaGhp2WWd3++CNvMcGAKCXdvdpYStXroznn38+Wlpauq/SRERs3rx5n9b66Ec/Gh/96Edj69atsXr16rjqqqvizDPPjP/+7/+O8ePH73bOAQccEIMGDYq2trZd7nv++ecjIuLAAw/ssb/Un4B2wAEHdF8hmjdv3m7HTJgwISIi3v72t0d7e/su9+9uH7yRYAMAUEI7g8HON+/vdMstt5Tk8UeMGBHNzc2xbdu2mDlzZjzxxBNvGmxGjBgRkydPjrvvvjuuu+66GD58eERE7NixI773ve/F2LFj47DDDitJXW+mtrY2pk2bFmvXro1jjjmm+4rO7kybNi2uvfbaeOyxx3r8Ododd9zRpzVSGQQbAIASmjJlShxwwAFx0UUXxVVXXRVDhw6N22+/PR577LFeP+aFF14Yw4cPj7/+67+OxsbGaG9vj8WLF0exWIwTTjhhj3MXL14c06dPj2nTpsVnPvOZGDZsWNx0003xm9/8Ju68885++Y6af/3Xf42TTz45TjnllPjEJz4RhxxySGzZsiWefvrp+PGPf9z9SXELFiyIb3/72/GhD30ovvzlL3d/Ktrvfve7Pq+R9HmPDQBACb397W+P5cuXR21tbZx//vlxwQUXxP777x933XVXrx/zlFNOid/85jfx6U9/OqZPnx7/+I//GIcddlj8/Oc/j4MOOmiPc6dOnRorV66MESNGxNy5c+PDH/5wdHR0xLJly3b5qOe+cuSRR8avfvWrmDhxYvzTP/1TNDU1xcc+9rH4wQ9+0OPLRBsaGqK1tTWOPPLI+MQnPhHnn39+7LfffrFkyZJ+qZO0FbIsy8pdBAAAwL5wxQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIG3Bd07tixI55//vmoq6vrly+MAuD/ZVkWW7ZsiTFjxsSgQX73tZPeBFAeefrSgAs2zz//fIwbN67cZQBUtQ0bNsTYsWPLXcaAoTcBlNfe9KUB9+u4urq6cpcAUPW8Fvfk5wFQXnvzOtxnweamm26KCRMmxH777RfHHXdc/PznP9+reS7xA5RfJb4W97YvRVTmzwMgJXvzOtwnweauu+6KBQsWxJVXXhlr166NU045JZqbm+PZZ5/ti+UAYI/0JYDKV8iyLCv1g06ePDne8573xM0339y974gjjoiZM2fG4sWL9zi3s7MzisViqUsCIIeOjo6or68vdxklsy99KUJvAii3velLJb9is23btnjkkUeiqampx/6mpqZ44IEHdhnf1dUVnZ2dPTYAKJW8fSlCbwJIUcmDzQsvvBCvvfZajB49usf+0aNHR3t7+y7jFy9eHMVisXvzqTMAlFLevhShNwGkqM8+POCNb/DJsmy3b/q5/PLLo6Ojo3vbsGFDX5UEQBXb274UoTcBpKjk32Nz4IEHxuDBg3f5LdjGjRt3+W1ZRERNTU3U1NSUugwAiIj8fSlCbwJIUcmv2AwbNiyOO+64WLFiRY/9K1asiClTppR6OQDYI30JoDqU/IpNRMTChQvjIx/5SBx//PHx3ve+N/793/89nn322bjooov6YjkA2CN9CaDy9UmwOeecc2LTpk3xxS9+Mdra2mLixIlx7733xvjx4/tiOQDYI30JoPL1yffY7AvfFQBQfpX2PTb7Sm8CKK+yfI8NAABAfxNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5Q8pdAAAAleGaa67JNf7www/Pvca8efNyz7nuuutyjT/33HNzr/Hqq6/mGp/3ZxUR8YUvfCH3nGriig0AAJA8wQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkjek3AVAfxo8eHDuOcVisQ8q2Xfz58/PNb62tjb3GocffnjuOfPmzcs1/rrrrsu9xrnnnptr/Kuvvpp7jWuuuSb3nC984Qu55wCVJ2+vqZQ+ExFx6aWX5hr/3HPP5V7jxhtvzD1n1qxZucZv2bIl9xqPPfZYrvGtra2512DPXLEBAACSJ9gAAADJK3mwWbRoURQKhR5bQ0NDqZcBgL2mNwFUvj55j81RRx0V//mf/9l9uzfvawCAUtKbACpbnwSbIUOG+E0YAAOK3gRQ2frkPTbr1q2LMWPGxIQJE+LDH/5wPPPMM286tqurKzo7O3tsAFBqehNAZSt5sJk8eXLcdtttcd9998U3v/nNaG9vjylTpsSmTZt2O37x4sVRLBa7t3HjxpW6JACqnN4EUPlKHmyam5vjrLPOiqOPPjo+8IEPxPLlyyMi4tZbb93t+Msvvzw6Ojq6tw0bNpS6JACqnN4EUPn6/As6R4wYEUcffXSsW7dut/fX1NRETU1NX5cBAN30JoDK0+ffY9PV1RW//e1vo7Gxsa+XAoC9ojcBVJ6SB5vPfOYz0draGuvXr4+HHnoozj777Ojs7Iw5c+aUeikA2Ct6E0DlK/mfoj333HNx7rnnxgsvvBAHHXRQnHTSSfHggw/G+PHjS70UAOwVvQmg8hWyLMvKXcTrdXZ2RrFYLHcZvMHBBx+ca/ywYcNyrzFlypTcc04++eRc49/2trflXuOss87KPadSPPfcc7nnrFmzJtf4WbNm5V5j69atucY/9thjudf4/Oc/n3tOS0tL7jkDVUdHR9TX15e7jAFDbxqY/uqv/irX+P7oMxH5e00195m5c+fmnvPSSy+VvpA3aGtryz3nxRdfzDX+qaeeyr1GNdubvtTn77EBAADoa4INAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5gg0AAJA8wQYAAEheIcuyrNxFvF5nZ2cUi8Vyl1HRjj322NxzVq5cmWu8czjw7NixI/ecCy64IPecl156KfecvNra2nKNf/HFF3Ov8dRTT+WeU0k6Ojqivr6+3GUMGHpT3zv44INzz1m/fn0fVMK+yNtrhg4d2keVUGn2pi+5YgMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5A0pdwH0v2effTb3nE2bNuUaXywWc69RKR566KHcczZv3px7zrRp03KN37ZtW+41vvvd7+aeAxARceyxx+Yav3Llyr4ppELl7TX90WcietdroFRcsQEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5A0pdwH0vz/96U+551x66aW5xp955pm511i7dm3uOTfeeGPuOXk9+uijucZPnz499xpbt27NPeeoo47KNf7Tn/507jUAeuvZZ5/NNX7Tpk251ygWi7nGf+pTn8q9xkDsMxH5e01v+kxv5O1NUEqu2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYUsy7JyF/F6nZ2dUSwWy10G+6i+vj73nC1btuSec8stt+Qa/7GPfSz3Gueff36u8XfeeWfuNWCg6ejo6NV/x5VKb+p7M2fOzD3nzDPPzDX+wgsvzL1Gb+hNUHp705dcsQEAAJIn2AAAAMnLHWxWr14dM2bMiDFjxkShUIh77rmnx/1ZlsWiRYtizJgxMXz48Dj11FPjiSeeKFW9ANCDvgRARC+CzdatW2PSpEmxZMmS3d5/7bXXxg033BBLliyJNWvWRENDQ0yfPr1X758AgLeiLwEQETEk74Tm5uZobm7e7X1ZlsXXvva1uPLKK2P27NkREXHrrbfG6NGj44477oiPf/zj+1YtALyBvgRARInfY7N+/fpob2+Ppqam7n01NTUxderUeOCBB3Y7p6urKzo7O3tsAFAKvelLEXoTQIpKGmza29sjImL06NE99o8ePbr7vjdavHhxFIvF7m3cuHGlLAmAKtabvhShNwGkqE8+Fa1QKPS4nWXZLvt2uvzyy6Ojo6N727BhQ1+UBEAVy9OXIvQmgBTlfo/NnjQ0NETEX35D1tjY2L1/48aNu/y2bKeampqoqakpZRkAEBG960sRehNAikp6xWbChAnR0NAQK1as6N63bdu2aG1tjSlTppRyKQB4S/oSQPXIfcXmpZdeiqeffrr79vr16+PRRx+NkSNHxsEHHxwLFiyIq6++Og499NA49NBD4+qrr47a2to477zzSlo4AEToSwD8Re5g8/DDD8e0adO6by9cuDAiIubMmRPf+c534rLLLotXXnklPvnJT8aLL74YkydPjvvvvz/q6upKVzUA/B99CYCIiEKWZVm5i3i9zs7OKBaL5S6DRHz1q1/NNX7n//Dk0drammv8Bz7wgdxr7NixI/cc6EsdHR1RX19f7jIGDL2JPPQmKL296Ut98qloAAAA/UmwAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJK2RZlpW7iNfr7OyMYrFY7jJIxIgRI3KN//GPf5x7jalTp+Ya39zcnHuN+++/P/cc6EsdHR1RX19f7jIGDL2JPPQmKL296Uuu2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYUsy7JyF/F6nZ2dUSwWy10GFepd73pX7jm/+tWvco3fvHlz7jVWrVqVe87DDz+ca/w3vvGN3GsMsJcH+lFHR0fU19eXu4wBQ2+iL+lN+TQ0NOSe09bWlnsOA8ve9CVXbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYUsy7JyF/F6nZ2dUSwWy10GdJs1a1au8UuXLs29Rl1dXe45eV1xxRW559x2222557S1teWew8DT0dER9fX15S5jwNCbGGiquTeNHz8+95yvfOUrucb/8Y9/zL0GfWtv+pIrNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABIXiHLsqzcRbxeZ2dnFIvFcpcBvTZx4sTcc2644Ybcc97//vfnnpPXLbfcknvOV77ylVzj//jHP+Zeg77X0dER9fX15S5jwNCbSF2196ZDDz001/jp06fnXoO+tTd9yRUbAAAgeYINAACQvNzBZvXq1TFjxowYM2ZMFAqFuOeee3rcP3fu3CgUCj22k046qVT1AkAP+hIAEb0INlu3bo1JkybFkiVL3nTM6aefHm1tbd3bvffeu09FAsCb0ZcAiIgYkndCc3NzNDc373FMTU1NNDQ09LooANhb+hIAEX30HpuWlpYYNWpUHHbYYXHhhRfGxo0b33RsV1dXdHZ29tgAoJTy9KUIvQkgRSUPNs3NzXH77bfHypUr4/rrr481a9bEaaedFl1dXbsdv3jx4igWi93buHHjSl0SAFUsb1+K0JsAUpT7T9HeyjnnnNP974kTJ8bxxx8f48ePj+XLl8fs2bN3GX/55ZfHwoULu293dnZqIACUTN6+FKE3AaSo5MHmjRobG2P8+PGxbt263d5fU1MTNTU1fV0GAETEW/elCL0JIEV9/j02mzZtig0bNkRjY2NfLwUAb0lfAqhMua/YvPTSS/H00093316/fn08+uijMXLkyBg5cmQsWrQozjrrrGhsbIzf//73ccUVV8SBBx4Ys2bNKmnhABChLwHwF7mDzcMPPxzTpk3rvr3zb5DnzJkTN998czz++ONx2223xebNm6OxsTGmTZsWd911V9TV1ZWuagD4P/oSABERhSzLsnIX8XqdnZ1RLBbLXQb0q7e97W2558yYMSPX+KVLl+Zeo1Ao5J6zcuXKXOOnT5+eew36XkdHR9TX15e7jAFDb6IaVVJv2r59e67xH/zgB3Ov0dLSknsOe29v+lKfv8cGAACgrwk2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5hSzLsnIX8XqdnZ1RLBbLXQZUnK6urtxzhgwZknvO9u3bc43/4Ac/mHuNlpaW3HPIp6OjI+rr68tdxoChN0Hf6E1v6o28/ezXv/517jWOO+64XON37NiRe41qtjd9yRUbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRvSLkLgEpzzDHH5J5z9tln555zwgkn5Bo/ZEj//Of+5JNP5hq/evXqPqoEgH3RH/1s5cqVuddoamrKPee1117LNb6trS33Gjt27Mg9h9JyxQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRtS7gKgPx1++OG558yfPz/X+NmzZ+deo6GhIfec/vDaa6/lntPW1pZr/I4dO3KvAVDt8vazvL0sorL62dlnn51r/LJly/qoEvqSKzYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkLwh5S4AdmpoaMg959xzz801fv78+bnXOOSQQ3LPGYgefvjh3HO+8pWv5J6zbNmy3HMAKknefpa3l0Xk72eV0ssietfPqA6u2AAAAMkTbAAAgOTlCjaLFy+OE044Ierq6mLUqFExc+bMeOqpp3qMybIsFi1aFGPGjInhw4fHqaeeGk888URJiwaAnfQmACJyBpvW1taYN29ePPjgg7FixYrYvn17NDU1xdatW7vHXHvttXHDDTfEkiVLYs2aNdHQ0BDTp0+PLVu2lLx4ANCbAIjI+eEBP/3pT3vcXrp0aYwaNSoeeeSReN/73hdZlsXXvva1uPLKK2P27NkREXHrrbfG6NGj44477oiPf/zjpascAEJvAuAv9uk9Nh0dHRERMXLkyIiIWL9+fbS3t0dTU1P3mJqampg6dWo88MADu32Mrq6u6Ozs7LEBQG/pTQDVqdfBJsuyWLhwYZx88skxceLEiIhob2+PiIjRo0f3GDt69Oju+95o8eLFUSwWu7dx48b1tiQAqpzeBFC9eh1s5s+fH7/+9a/jzjvv3OW+QqHQ43aWZbvs2+nyyy+Pjo6O7m3Dhg29LQmAKqc3AVSvXn1B58UXXxzLli2L1atXx9ixY7v37/xCqvb29mhsbOzev3Hjxl1+U7ZTTU1N1NTU9KYMAOimNwFUt1xXbLIsi/nz58fdd98dK1eujAkTJvS4f8KECdHQ0BArVqzo3rdt27ZobW2NKVOmlKZiAHgdvQmAiJxXbObNmxd33HFH/OhHP4q6urruv00uFosxfPjwKBQKsWDBgrj66qvj0EMPjUMPPTSuvvrqqK2tjfPOO69PDgCA6qY3ARCRM9jcfPPNERFx6qmn9ti/dOnSmDt3bkREXHbZZfHKK6/EJz/5yXjxxRdj8uTJcf/990ddXV1JCgaA19ObAIiIKGRZlpW7iNfr7OyMYrFY7jJ4gzf7O/Q3c+SRR+ZeY8mSJbnnvPvd7849ZyB66KGHcs/56le/mmv8j370o9xr7NixI/ccKkNHR0fU19eXu4wBQ28ijyeeeCLX+ErpZRH5+1neXhahn1WrvelL+/Q9NgAAAAOBYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkjek3AWw70aOHJlr/C233JJ7jWOPPTbX+He+85251xioHnjggVzjr7/++txr3HfffbnnvPLKK7nnAFSz0aNH555z5JFH9kEl/S9vL4von36ml1FKrtgAAADJE2wAAIDkCTYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHlDyl1AJZs8eXLuOZdeemnuOSeeeGKu8e94xztyrzFQvfzyy7nG33jjjbnXuPrqq3ON37p1a+41AKrdyJEjc8+55ZZbco0/9thjc6/xzne+M/ecvPL2soj8/SxvL4vQz0iPKzYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRPsAEAAJIn2AAAAMkTbAAAgOQJNgAAQPIEGwAAIHmCDQAAkDzBBgAASN6QchdQyWbNmtUvc/rDk08+mWv8T37yk9xrbN++Pfec66+/Ptf4zZs3514DoNpNnjw595xLL7001/gTTzwx9xrveMc7cs8ZiMaNG5d7jn4Gu3LFBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSN6TcBVSyz33uc/0yBwD60qxZs/plTl978sknc8/5yU9+knvO9u3bc43fvHlz7jWAXbliAwAAJE+wAQAAkpcr2CxevDhOOOGEqKuri1GjRsXMmTPjqaee6jFm7ty5USgUemwnnXRSSYsGgJ30JgAicgab1tbWmDdvXjz44IOxYsWK2L59ezQ1NcXWrVt7jDv99NOjra2te7v33ntLWjQA7KQ3ARCR88MDfvrTn/a4vXTp0hg1alQ88sgj8b73va97f01NTTQ0NJSmQgDYA70JgIh9fI9NR0dHRESMHDmyx/6WlpYYNWpUHHbYYXHhhRfGxo0b3/Qxurq6orOzs8cGAL2lNwFUp14HmyzLYuHChXHyySfHxIkTu/c3NzfH7bffHitXrozrr78+1qxZE6eddlp0dXXt9nEWL14cxWKxexs3blxvSwKgyulNANWrkGVZ1puJ8+bNi+XLl8cvfvGLGDt27JuOa2tri/Hjx8f3v//9mD179i73d3V19WgsnZ2dGghAmXV0dER9fX25y8hNb+ob11xzTe45l156aR9Usm8G6vfYfP7zn8+9BlSbvelLvfqCzosvvjiWLVsWq1ev3mPjiIhobGyM8ePHx7p163Z7f01NTdTU1PSmDADopjcBVLdcwSbLsrj44ovjhz/8YbS0tMSECRPecs6mTZtiw4YN0djY2OsiAeDN6E0AROR8j828efPie9/7Xtxxxx1RV1cX7e3t0d7eHq+88kpERLz00kvxmc98Jn75y1/G73//+2hpaYkZM2bEgQceGLNmzeqTAwCguulNAETkvGJz8803R0TEqaee2mP/0qVLY+7cuTF48OB4/PHH47bbbovNmzdHY2NjTJs2Le66666oq6srWdEAsJPeBEDEPnx4QF/p7OyMYrFY7jIAqlqqHx7QV/QmgPLam760T99jAwAAMBAINgAAQPIEGwAAIHmCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAkT7ABAACSJ9gAAADJE2wAAIDkCTYAAEDyBBsAACB5gg0AAJA8wQYAAEieYAMAACRPsAEAAJI34IJNlmXlLgGg6nkt7snPA6C89uZ1eMAFmy1btpS7BICq57W4Jz8PgPLam9fhQjbAfg21Y8eOeP7556Ouri4KhUKP+zo7O2PcuHGxYcOGqK+vL1OF5eHYq+/Yq/W4Ixx7OY89y7LYsmVLjBkzJgYNGnC/+yqbN+tN5T5f5eTYHbtjrx7lPPY8fWlIP9W01wYNGhRjx47d45j6+vqqe0Lt5Nir79ir9bgjHHu5jr1YLJZl3YHsrXqT56pjrzaO3bH3p73tS34dBwAAJE+wAQAAkpdUsKmpqYmrrroqampqyl1Kv3Ps1Xfs1XrcEY69Wo89RdV8vhy7Y682jn3gH/uA+/AAAACAvJK6YgMAALA7gg0AAJA8wQYAAEieYAMAACQvmWBz0003xYQJE2K//faL4447Ln7+85+Xu6Q+t2jRoigUCj22hoaGcpfVJ1avXh0zZsyIMWPGRKFQiHvuuafH/VmWxaJFi2LMmDExfPjwOPXUU+OJJ54oT7El9lbHPnfu3F2eByeddFJ5ii2xxYsXxwknnBB1dXUxatSomDlzZjz11FM9xlTiud+b467k815J9Ca9qdJen3aq1t5UrX0pojJ6UxLB5q677ooFCxbElVdeGWvXro1TTjklmpub49lnny13aX3uqKOOira2tu7t8ccfL3dJfWLr1q0xadKkWLJkyW7vv/baa+OGG26IJUuWxJo1a6KhoSGmT58eW7Zs6edKS++tjj0i4vTTT+/xPLj33nv7scK+09raGvPmzYsHH3wwVqxYEdu3b4+mpqbYunVr95hKPPd7c9wRlXveK4XepDdV4uvTTtXam6q1L0VUSG/KEnDiiSdmF110UY997373u7PPfe5zZaqof1x11VXZpEmTyl1Gv4uI7Ic//GH37R07dmQNDQ3ZNddc073v1VdfzYrFYvZv//ZvZaiw77zx2LMsy+bMmZP97d/+bVnq6W8bN27MIiJrbW3Nsqx6zv0bjzvLquu8p0pvqi560w977KuW16hq7UtZlmZvGvBXbLZt2xaPPPJINDU19djf1NQUDzzwQJmq6j/r1q2LMWPGxIQJE+LDH/5wPPPMM+Uuqd+tX78+2tvbezwHampqYurUqVXxHIiIaGlpiVGjRsVhhx0WF154YWzcuLHcJfWJjo6OiIgYOXJkRFTPuX/jce9ULec9RXqT3lQtr097Ug2vUdXalyLS7E0DPti88MIL8dprr8Xo0aN77B89enS0t7eXqar+MXny5Ljtttvivvvui29+85vR3t4eU6ZMiU2bNpW7tH618zxX43MgIqK5uTluv/32WLlyZVx//fWxZs2aOO2006Krq6vcpZVUlmWxcOHCOPnkk2PixIkRUR3nfnfHHVE95z1VepPeVA2vT3tSDa9R1dqXItLtTUPKXcDeKhQKPW5nWbbLvkrT3Nzc/e+jjz463vve98a73vWuuPXWW2PhwoVlrKw8qvE5EBFxzjnndP974sSJcfzxx8f48eNj+fLlMXv27DJWVlrz58+PX//61/GLX/xil/sq+dy/2XFXy3lPXSU/N9+M3tRTNT4HIqrjNapa+1JEur1pwF+xOfDAA2Pw4MG7pOCNGzfukpYr3YgRI+Loo4+OdevWlbuUfrXz03Y8B/6isbExxo8fX1HPg4svvjiWLVsWq1atirFjx3bvr/Rz/2bHvTuVeN5Tpjf9P73JcyCi8l6jqrUvRaTdmwZ8sBk2bFgcd9xxsWLFih77V6xYEVOmTClTVeXR1dUVv/3tb6OxsbHcpfSrCRMmRENDQ4/nwLZt26K1tbXqngMREZs2bYoNGzZUxPMgy7KYP39+3H333bFy5cqYMGFCj/sr9dy/1XHvTiWd90qgN/0/vamyXp96q1Jeo6q1L0VUSG8qxycW5PX9738/Gzp0aPatb30re/LJJ7MFCxZkI0aMyH7/+9+Xu7Q+dckll2QtLS3ZM888kz344IPZmWeemdXV1VXkcW/ZsiVbu3Zttnbt2iwishtuuCFbu3Zt9oc//CHLsiy75pprsmKxmN19993Z448/np177rlZY2Nj1tnZWebK992ejn3Lli3ZJZdckj3wwAPZ+vXrs1WrVmXvfe97s3e84x0Vceyf+MQnsmKxmLW0tGRtbW3d28svv9w9phLP/Vsdd6Wf90qhN+lNlfj6tFO19qZq7UtZVhm9KYlgk2VZ9o1vfCMbP358NmzYsOw973lPj4+eq1TnnHNO1tjYmA0dOjQbM2ZMNnv27OyJJ54od1l9YtWqVVlE7LLNmTMny7K/fLziVVddlTU0NGQ1NTXZ+973vuzxxx8vb9Elsqdjf/nll7OmpqbsoIMOyoYOHZodfPDB2Zw5c7Jnn3223GWXxO6OOyKypUuXdo+pxHP/Vsdd6ee9kuhNelOlvT7tVK29qVr7UpZVRm8qZFmWlf46EAAAQP8Z8O+xAQAAeCuCDQAAkDzBBgAASJ5gAwAAJE+wAQAAkifYAAAAyRNsAACA5Ak2AABA8gQbAAAgeYINAACQPMEGAABInmADAAAk738Bryfku5HGTBMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2, label = mnist_train[0]\n",
    "\n",
    "# plot 2 images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(img, cmap=\"gray\")\n",
    "axs[1].imshow((img2.permute(1, 2, 0) * 255).numpy().astype(\"uint8\"), cmap=\"gray\")\n",
    "plt.title(\"Transformed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to add the `ToTensor` transformation to the `test_transform` since we want to convert the images to tensors before feeding them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test.transform = T.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model using SGD, we need to pack the data into batches. This is done using `DataLoader` which is a subclass of `torch.utils.data.DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataLoader implements the iterator pattern in a **lazy way** (using a generator):\n",
    "- We cannot access the batches directly (e.g., `trainloader[0]` does not work)\n",
    "- We create a dataset by iterating over the DataLoader or by calling the `next` method on `iter(dataloader)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 2 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 3 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 4 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 5 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 6 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 7 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 8 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 9 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 10 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 11 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 12 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 13 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 14 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 15 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 16 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 17 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 18 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 19 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 20 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 21 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 22 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 23 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 24 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 25 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 26 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 27 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 28 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 29 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 30 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 31 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 32 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 33 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 34 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 35 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 36 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 37 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 38 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 39 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 40 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 41 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 42 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 43 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 44 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 45 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 46 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 47 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 48 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 49 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 50 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 51 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 52 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 53 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 54 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 55 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 56 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 57 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 58 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 59 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 60 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 61 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 62 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 63 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 64 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 65 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 66 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 67 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 68 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 69 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 70 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 71 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 72 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 73 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 74 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 75 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 76 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 77 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 78 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 79 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 80 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 81 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 82 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 83 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 84 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 85 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 86 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 87 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 88 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 89 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 90 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 91 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 92 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 93 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 94 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 95 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 96 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 97 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 98 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 99 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 100 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 101 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 102 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 103 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 104 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 105 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 106 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 107 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 108 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 109 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 110 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 111 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 112 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 113 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 114 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 115 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 116 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 117 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 118 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 119 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 120 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 121 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 122 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 123 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 124 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 125 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 126 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 127 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 128 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 129 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 130 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 131 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 132 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 133 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 134 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 135 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 136 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 137 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 138 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 139 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 140 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 141 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 142 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 143 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 144 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 145 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 146 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 147 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 148 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 149 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 150 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 151 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 152 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 153 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 154 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 155 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 156 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 157 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 158 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 159 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 160 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 161 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 162 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 163 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 164 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 165 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 166 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 167 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 168 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 169 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 170 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 171 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 172 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 173 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 174 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 175 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 176 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 177 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 178 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 179 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 180 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 181 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 182 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 183 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 184 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 185 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 186 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 187 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 188 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 189 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 190 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 191 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 192 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 193 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 194 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 195 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 196 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 197 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 198 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 199 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 200 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 201 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 202 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 203 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 204 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 205 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 206 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 207 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 208 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 209 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 210 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 211 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 212 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 213 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 214 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 215 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 216 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 217 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 218 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 219 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 220 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 221 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 222 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 223 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 224 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 225 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 226 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 227 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 228 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 229 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 230 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 231 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 232 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 233 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 234 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 235 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 236 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 237 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 238 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 239 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 240 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 241 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 242 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 243 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 244 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 245 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 246 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 247 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 248 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 249 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 250 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 251 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 252 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 253 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 254 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 255 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 256 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 257 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 258 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 259 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 260 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 261 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 262 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 263 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 264 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 265 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 266 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 267 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 268 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 269 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 270 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 271 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 272 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 273 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 274 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 275 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 276 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 277 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 278 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 279 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 280 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 281 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 282 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 283 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 284 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 285 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 286 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 287 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 288 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 289 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 290 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 291 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 292 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 293 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 294 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 295 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 296 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 297 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 298 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 299 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 300 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 301 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 302 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 303 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 304 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 305 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 306 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 307 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 308 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 309 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 310 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 311 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 312 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 313 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 314 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 315 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 316 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 317 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 318 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 319 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 320 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 321 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 322 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 323 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 324 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 325 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 326 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 327 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 328 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 329 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 330 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 331 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 332 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 333 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 334 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 335 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 336 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 337 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 338 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 339 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 340 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 341 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 342 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 343 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 344 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 345 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 346 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 347 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 348 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 349 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 350 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 351 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 352 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 353 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 354 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 355 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 356 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 357 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 358 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 359 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 360 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 361 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 362 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 363 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 364 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 365 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 366 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 367 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 368 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 369 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 370 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 371 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 372 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 373 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 374 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 375 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 376 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 377 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 378 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 379 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 380 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 381 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 382 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 383 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 384 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 385 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 386 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 387 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 388 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 389 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 390 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 391 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 392 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 393 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 394 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 395 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 396 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 397 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 398 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 399 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 400 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 401 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 402 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 403 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 404 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 405 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 406 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 407 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 408 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 409 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 410 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 411 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 412 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 413 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 414 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 415 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 416 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 417 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 418 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 419 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 420 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 421 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 422 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 423 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 424 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 425 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 426 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 427 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 428 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 429 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 430 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 431 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 432 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 433 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 434 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 435 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 436 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 437 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 438 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 439 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 440 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 441 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 442 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 443 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 444 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 445 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 446 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 447 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 448 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 449 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 450 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 451 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 452 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 453 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 454 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 455 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 456 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 457 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 458 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 459 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 460 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 461 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 462 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 463 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 464 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 465 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 466 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 467 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 468 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 469 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 470 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 471 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 472 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 473 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 474 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 475 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 476 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 477 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 478 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 479 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 480 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 481 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 482 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 483 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 484 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 485 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 486 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 487 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 488 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 489 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 490 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 491 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 492 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 493 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 494 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 495 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 496 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 497 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 498 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 499 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 500 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 501 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 502 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 503 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 504 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 505 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 506 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 507 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 508 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 509 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 510 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 511 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 512 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 513 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 514 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 515 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 516 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 517 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 518 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 519 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 520 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 521 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 522 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 523 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 524 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 525 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 526 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 527 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 528 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 529 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 530 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 531 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 532 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 533 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 534 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 535 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 536 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 537 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 538 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 539 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 540 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 541 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 542 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 543 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 544 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 545 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 546 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 547 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 548 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 549 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 550 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 551 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 552 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 553 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 554 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 555 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 556 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 557 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 558 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 559 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 560 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 561 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 562 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 563 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 564 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 565 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 566 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 567 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 568 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 569 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 570 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 571 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 572 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 573 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 574 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 575 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 576 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 577 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 578 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 579 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 580 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 581 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 582 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 583 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 584 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 585 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 586 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 587 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 588 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 589 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 590 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 591 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 592 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 593 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 594 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 595 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 596 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 597 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 598 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 599 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 600 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 601 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 602 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 603 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 604 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 605 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 606 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 607 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 608 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 609 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 610 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 611 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 612 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 613 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 614 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 615 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 616 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 617 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 618 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 619 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 620 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 621 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 622 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 623 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 624 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 625 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 626 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 627 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 628 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 629 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 630 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 631 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 632 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 633 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 634 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 635 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 636 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 637 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 638 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 639 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 640 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 641 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 642 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 643 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 644 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 645 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 646 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 647 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 648 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 649 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 650 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 651 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 652 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 653 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 654 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 655 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 656 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 657 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 658 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 659 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 660 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 661 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 662 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 663 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 664 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 665 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 666 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 667 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 668 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 669 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 670 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 671 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 672 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 673 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 674 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 675 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 676 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 677 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 678 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 679 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 680 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 681 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 682 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 683 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 684 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 685 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 686 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 687 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 688 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 689 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 690 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 691 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 692 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 693 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 694 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 695 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 696 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 697 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 698 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 699 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 700 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 701 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 702 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 703 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 704 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 705 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 706 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 707 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 708 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 709 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 710 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 711 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 712 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 713 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 714 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 715 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 716 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 717 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 718 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 719 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 720 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 721 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 722 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 723 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 724 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 725 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 726 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 727 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 728 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 729 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 730 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 731 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 732 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 733 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 734 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 735 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 736 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 737 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 738 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 739 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 740 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 741 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 742 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 743 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 744 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 745 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 746 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 747 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 748 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 749 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 750 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 751 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 752 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 753 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 754 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 755 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 756 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 757 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 758 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 759 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 760 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 761 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 762 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 763 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 764 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 765 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 766 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 767 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 768 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 769 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 770 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 771 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 772 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 773 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 774 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 775 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 776 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 777 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 778 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 779 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 780 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 781 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 782 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 783 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 784 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 785 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 786 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 787 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 788 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 789 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 790 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 791 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 792 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 793 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 794 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 795 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 796 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 797 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 798 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 799 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 800 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 801 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 802 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 803 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 804 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 805 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 806 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 807 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 808 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 809 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 810 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 811 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 812 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 813 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 814 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 815 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 816 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 817 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 818 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 819 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 820 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 821 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 822 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 823 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 824 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 825 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 826 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 827 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 828 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 829 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 830 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 831 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 832 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 833 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 834 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 835 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 836 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 837 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 838 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 839 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 840 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 841 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 842 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 843 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 844 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 845 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 846 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 847 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 848 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 849 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 850 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 851 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 852 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 853 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 854 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 855 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 856 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 857 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 858 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 859 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 860 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 861 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 862 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 863 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 864 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 865 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 866 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 867 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 868 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 869 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 870 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 871 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 872 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 873 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 874 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 875 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 876 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 877 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 878 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 879 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 880 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 881 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 882 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 883 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 884 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 885 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 886 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 887 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 888 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 889 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 890 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 891 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 892 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 893 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 894 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 895 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 896 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 897 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 898 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 899 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 900 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 901 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 902 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 903 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 904 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 905 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 906 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 907 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 908 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 909 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 910 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 911 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 912 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 913 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 914 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 915 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 916 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 917 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 918 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 919 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 920 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 921 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 922 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 923 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 924 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 925 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 926 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 927 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 928 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 929 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 930 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 931 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 932 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 933 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 934 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 935 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 936 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 937 torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "Batch 938 torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(trainloader):\n",
    "    print(f\"Batch {i+1}\", batch[0].shape, batch[1].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the model. We'll be using a simple MLP with 3 hidden layers, relu activations, and batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Linear(16, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, our model needs an **optimizer** to update the weights. We'll use the `torch.optim.SGD` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build the training loop.\n",
    "\n",
    "We define a number of epochs for training. In each epoch, we'll *regenerate* the trainloader to redo the batches and apply the random transformations to the images.\n",
    "\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "    for data, labels in trainloader:\n",
    "        ...\n",
    "```\n",
    "\n",
    "Within the inner loop, we will need to do the following things:\n",
    "- Zero out the gradients from the previous iteration\n",
    "- Do the forward pass\n",
    "- Compute the loss\n",
    "- Do the backward pass\n",
    "- Update the weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.train() # IMPORTANT: this sets the model to training mode --- useful for batchnorm and dropout\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data, labels in trainloader:\n",
    "        # inner loop\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to compute some other metrics while the model is training.\n",
    "\n",
    "We can use `torcheval` functionalities to keep track of accuracy and loss.\n",
    "\n",
    "In addition, we can use `tqdm` to display a progress bar.\n",
    "\n",
    "We will also anneal the learning rate at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 938/938 [00:17<00:00, 52.93it/s, accuracy=0.86, loss=0.466] \n",
      "Epoch 2/3: 100%|██████████| 938/938 [00:17<00:00, 52.96it/s, accuracy=0.917, loss=0.273]\n",
      "Epoch 3/3: 100%|██████████| 938/938 [00:18<00:00, 51.78it/s, accuracy=0.921, loss=0.263]\n"
     ]
    }
   ],
   "source": [
    "mlp.train() # IMPORTANT: this sets the model to training mode --- useful for batchnorm and dropout\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1) # will anneal LR by 0.1 each time scheduler.step() is called\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    accuracy_counter = metrics.MulticlassAccuracy()\n",
    "    loss_counter = metrics.Mean()\n",
    "\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for data, labels in progress_bar:\n",
    "        # some code here\n",
    "\n",
    "        accuracy_counter.update(predictions, labels)\n",
    "        loss_counter.update(loss, weight=data.size(0))\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            loss=loss_counter.compute().item(),\n",
    "            accuracy=accuracy_counter.compute().item()\n",
    "        )\n",
    "    scheduler.step() # anneal LR by 0.1\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evaluation is done in a similar way to the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 157/157 [00:00<00:00, 235.10it/s, accuracy=0.945, loss=0.18] \n"
     ]
    }
   ],
   "source": [
    "mlp.eval() # IMPORTANT: this sets the model to evaluation mode --- useful for batchnorm and dropout\n",
    "\n",
    "accuracy_counter = metrics.MulticlassAccuracy()\n",
    "loss_counter = metrics.Mean()\n",
    "\n",
    "progress_bar = tqdm(testloader, desc=f\"Eval 1/1\")\n",
    "for data, labels in progress_bar:\n",
    "    with torch.no_grad(): # force no gradients\n",
    "        # some code here\n",
    "\n",
    "\n",
    "        accuracy_counter.update(predictions, labels)\n",
    "        loss_counter.update(loss, weight=data.size(0))\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            loss=loss_counter.compute().item(),\n",
    "            accuracy=accuracy_counter.compute().item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bundle together all the components to train and eval the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, trainloader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        accuracy_counter = metrics.MulticlassAccuracy()\n",
    "        loss_counter = metrics.Mean()\n",
    "\n",
    "        progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for data, labels in progress_bar:\n",
    "\n",
    "            accuracy_counter.update(predictions, labels)\n",
    "            loss_counter.update(loss, weight=data.size(0))\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss=loss_counter.compute().item(),\n",
    "                accuracy=accuracy_counter.compute().item()\n",
    "            )\n",
    "        scheduler.step()\n",
    "\n",
    "def evaluate(model, testloader):\n",
    "    model.eval()\n",
    "    accuracy_counter = metrics.MulticlassAccuracy()\n",
    "    loss_counter = metrics.Mean()\n",
    "\n",
    "    progress_bar = tqdm(testloader, desc=\"Eval 1/1\")\n",
    "    for data, labels in progress_bar:\n",
    "        with torch.no_grad():\n",
    "            \n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss=loss_counter.compute().item(),\n",
    "                accuracy=accuracy_counter.compute().item()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading a model\n",
    "\n",
    "We can save the model using `torch.save(model.state_dict(), save_path)` and load it using `model.load_state_dict(torch.load(save_path))`.\n",
    "\n",
    "The `state_dict` is a dictionary containing the model's parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1.weight',\n",
       "              tensor([[-0.0192, -0.0297,  0.0338,  ...,  0.0230,  0.0002,  0.0015],\n",
       "                      [ 0.0274, -0.0115,  0.0014,  ...,  0.0204,  0.0273,  0.0077],\n",
       "                      [-0.0342, -0.0156,  0.0007,  ..., -0.0044,  0.0201,  0.0230],\n",
       "                      ...,\n",
       "                      [-0.0049, -0.0301,  0.0041,  ..., -0.0319,  0.0206,  0.0270],\n",
       "                      [ 0.0324,  0.0323, -0.0011,  ...,  0.0133, -0.0038, -0.0199],\n",
       "                      [ 0.0065,  0.0144, -0.0102,  ...,  0.0056, -0.0267, -0.0072]])),\n",
       "             ('1.bias',\n",
       "              tensor([-0.0274, -0.0193,  0.0582,  0.0075,  0.0097,  0.1184,  0.0753, -0.0574,\n",
       "                       0.0827,  0.1902,  0.0269, -0.0406,  0.0780,  0.1205,  0.1526,  0.0323])),\n",
       "             ('3.weight',\n",
       "              tensor([0.9834, 0.9356, 0.9721, 0.9357, 0.9411, 1.0219, 0.9642, 0.9889, 0.9779,\n",
       "                      1.0161, 0.9885, 0.9817, 0.9504, 1.0194, 1.0541, 1.1152])),\n",
       "             ('3.bias',\n",
       "              tensor([ 0.0555,  0.0135, -0.1337,  0.0766, -0.0349,  0.0185,  0.1432,  0.0581,\n",
       "                       0.1011,  0.1205, -0.0724, -0.1030, -0.0363,  0.0969,  0.0467,  0.0037])),\n",
       "             ('3.running_mean',\n",
       "              tensor([5.6052e-45, 5.6492e-01, 1.8329e+00, 5.1707e-01, 1.8023e+00, 5.2220e-01,\n",
       "                      5.9905e-01, 5.6052e-45, 1.6425e+00, 1.9664e+00, 6.5466e-01, 2.7612e-01,\n",
       "                      1.8563e+00, 1.5019e+00, 1.1240e+00, 2.5144e-01])),\n",
       "             ('3.running_var',\n",
       "              tensor([5.6052e-45, 5.6891e-01, 1.9593e+00, 6.3618e-01, 1.0552e+00, 5.5148e-01,\n",
       "                      8.3163e-01, 5.6052e-45, 1.4268e+00, 2.3541e+00, 6.4351e-01, 3.4027e-01,\n",
       "                      1.5057e+00, 1.2615e+00, 1.1894e+00, 4.4854e-01])),\n",
       "             ('3.num_batches_tracked', tensor(2814)),\n",
       "             ('4.weight',\n",
       "              tensor([[-9.0265e-02,  9.2953e-02, -2.0386e-01,  1.5131e-01,  4.3751e-02,\n",
       "                       -7.1691e-02, -3.7871e-02,  5.4167e-02,  1.0490e-01,  3.7528e-01,\n",
       "                       -3.3363e-01, -1.9802e-01, -1.7204e-01, -1.6282e-01, -3.8706e-01,\n",
       "                       -2.8295e-03],\n",
       "                      [ 5.0720e-02,  3.0362e-01,  1.3682e-01, -2.0510e-01, -6.1954e-02,\n",
       "                        1.5199e-01, -3.4617e-01,  3.4925e-02, -1.7956e-01,  1.4223e-01,\n",
       "                        3.6621e-01,  7.4016e-02, -1.1791e-01, -2.8526e-01,  5.9233e-02,\n",
       "                        3.6865e-01],\n",
       "                      [ 4.9075e-02,  2.4739e-01, -2.0695e-01, -1.3895e-01, -3.6924e-01,\n",
       "                        3.2605e-01,  2.8468e-01,  1.8796e-01,  1.0400e-02,  1.2479e-01,\n",
       "                        5.2343e-02,  1.0379e-01, -2.7575e-01,  6.7880e-02, -1.6754e-01,\n",
       "                       -2.2595e-01],\n",
       "                      [ 1.7941e-01,  9.5059e-02,  2.0725e-01,  1.4788e-01, -1.3837e-01,\n",
       "                       -1.8967e-01,  3.6675e-02,  2.1098e-01, -2.3601e-02,  3.7365e-01,\n",
       "                       -8.2580e-02,  2.1874e-01,  4.8516e-02, -1.9896e-01, -2.3174e-01,\n",
       "                       -1.7304e-02],\n",
       "                      [-2.4105e-01,  2.0766e-01, -5.0293e-02,  2.8503e-01, -2.3762e-01,\n",
       "                       -8.1478e-02, -1.9918e-01,  1.9663e-01, -2.4156e-01, -2.3771e-02,\n",
       "                       -2.9071e-01,  1.2855e-01,  8.7756e-02,  6.9506e-02,  4.2455e-01,\n",
       "                        8.0264e-02],\n",
       "                      [ 3.9001e-02, -1.7067e-01, -2.1257e-01, -2.0571e-01,  4.6274e-02,\n",
       "                        2.1909e-01, -9.5737e-04,  8.3293e-02,  3.9510e-01, -3.0071e-01,\n",
       "                        1.3077e-01, -7.5616e-03, -2.8888e-01,  1.7049e-01,  8.4612e-02,\n",
       "                       -3.6417e-01],\n",
       "                      [-6.9020e-02, -1.5312e-01, -2.7255e-01,  1.9359e-01, -6.8367e-02,\n",
       "                        1.8606e-01,  3.9539e-02,  5.9787e-02, -2.5516e-01, -3.9489e-01,\n",
       "                       -1.3523e-01,  1.2239e-01, -6.1491e-02,  5.1804e-03,  2.3371e-01,\n",
       "                       -8.0930e-02],\n",
       "                      [-2.2637e-01,  3.9222e-02, -1.8023e-01, -2.0954e-01, -3.7580e-01,\n",
       "                        3.9527e-02,  1.5861e-01, -2.3528e-01, -5.7670e-02,  2.2527e-01,\n",
       "                       -6.1766e-02,  8.4504e-02, -3.5593e-02,  3.0814e-01,  4.6611e-02,\n",
       "                        2.9054e-01],\n",
       "                      [-1.2477e-02, -2.3097e-01,  9.7997e-02, -1.9831e-01,  1.7680e-01,\n",
       "                       -1.3995e-01,  1.7023e-01,  2.3271e-02, -3.8742e-02,  2.6539e-01,\n",
       "                       -1.8994e-01,  1.2643e-01, -5.1701e-01,  1.1063e-01, -5.6253e-02,\n",
       "                        1.3664e-01],\n",
       "                      [-5.3702e-02, -3.4428e-02, -2.2525e-01,  9.5076e-02,  2.8577e-01,\n",
       "                       -4.1079e-02,  2.0970e-01,  2.5487e-02, -3.3791e-01, -2.6737e-01,\n",
       "                        3.9679e-01, -1.1717e-01, -2.3310e-02,  1.1222e-01, -3.4238e-02,\n",
       "                       -2.1347e-01],\n",
       "                      [ 3.7051e-02,  8.1903e-02, -4.5925e-01, -2.9622e-01,  8.1999e-04,\n",
       "                        2.1320e-02,  1.1002e-01, -2.1271e-01,  2.2834e-01,  1.4428e-01,\n",
       "                       -1.3073e-01, -1.1627e-01,  2.0513e-01, -1.0172e-01,  2.3547e-01,\n",
       "                       -8.8644e-02],\n",
       "                      [ 1.6307e-01, -2.8277e-01, -1.4411e-01,  1.5086e-01, -2.3541e-01,\n",
       "                       -9.4540e-02,  2.0920e-02,  1.4678e-01,  1.7906e-01,  1.5547e-01,\n",
       "                        2.8126e-01, -2.3689e-01, -1.5292e-02,  4.1002e-01,  5.7821e-02,\n",
       "                       -9.1463e-02],\n",
       "                      [-1.5714e-01,  1.4202e-01,  2.9674e-02,  5.6682e-03, -8.0560e-02,\n",
       "                        3.9238e-01, -2.2605e-01,  8.6559e-02,  1.4555e-01,  7.5026e-02,\n",
       "                       -9.7853e-02, -2.3620e-01, -3.8883e-03,  9.4181e-02, -2.8145e-01,\n",
       "                        3.8967e-01],\n",
       "                      [ 1.8531e-01, -6.6469e-05,  3.7706e-01,  4.9208e-02, -1.3352e-01,\n",
       "                        1.1936e-01, -1.4824e-01, -2.2082e-01,  1.8522e-02, -2.7844e-01,\n",
       "                       -1.0122e-01,  1.7137e-01, -2.2807e-01,  3.3362e-01,  2.4572e-01,\n",
       "                       -1.5778e-03],\n",
       "                      [ 2.3122e-01,  3.2061e-01, -1.4748e-01, -4.8987e-02,  6.3785e-02,\n",
       "                        1.3555e-01, -3.3320e-01, -3.6573e-02,  9.4504e-02, -7.5423e-02,\n",
       "                        1.2065e-02, -3.6047e-01,  1.0806e-02,  2.5724e-01, -7.3604e-03,\n",
       "                       -2.8467e-01],\n",
       "                      [ 1.3210e-01, -3.6227e-02,  2.0842e-01,  3.5184e-01,  3.4727e-03,\n",
       "                       -4.5404e-01,  3.5453e-01,  3.5114e-02, -3.4285e-03, -1.0946e-01,\n",
       "                       -9.3974e-02, -1.2034e-01, -2.7422e-01, -2.8540e-01,  2.0609e-01,\n",
       "                       -5.4872e-02]])),\n",
       "             ('4.bias',\n",
       "              tensor([-0.0168, -0.0443,  0.3115,  0.0110, -0.1107,  0.0273,  0.0492,  0.1696,\n",
       "                       0.1852, -0.0507,  0.3058,  0.0834,  0.1242, -0.0327,  0.2189,  0.0444])),\n",
       "             ('6.weight',\n",
       "              tensor([0.9936, 0.9907, 0.9659, 0.9430, 0.9214, 0.9227, 0.9340, 1.0089, 1.0809,\n",
       "                      0.9561, 1.0472, 0.9525, 1.0150, 1.0118, 0.9595, 1.0144])),\n",
       "             ('6.bias',\n",
       "              tensor([ 0.0370,  0.0039,  0.0983,  0.0033,  0.0375, -0.1212,  0.0960,  0.1062,\n",
       "                      -0.3291,  0.0542,  0.2362, -0.0733, -0.0050, -0.1674, -0.0066,  0.0041])),\n",
       "             ('6.running_mean',\n",
       "              tensor([0.3909, 0.2901, 0.5345, 0.3215, 0.1954, 0.3409, 0.4165, 0.4621, 0.4805,\n",
       "                      0.3197, 0.6448, 0.4121, 0.3969, 0.2529, 0.4358, 0.3565])),\n",
       "             ('6.running_var',\n",
       "              tensor([0.3097, 0.2254, 0.2706, 0.2509, 0.1383, 0.2009, 0.2750, 0.3478, 0.4060,\n",
       "                      0.1833, 0.4532, 0.2459, 0.3478, 0.1737, 0.2448, 0.2527])),\n",
       "             ('6.num_batches_tracked', tensor(2814)),\n",
       "             ('7.weight',\n",
       "              tensor([[-0.2143, -0.1227, -0.1457, -0.1399,  0.1026, -0.0132, -0.0035, -0.0354,\n",
       "                       -0.5212,  0.0528, -0.1606, -0.1542,  0.1105, -0.1640,  0.1942,  0.2822],\n",
       "                      [-0.0621,  0.3911,  0.0799, -0.2410,  0.0450, -0.2271,  0.1296,  0.0690,\n",
       "                       -0.1673,  0.1462, -0.1257, -0.1422, -0.2255,  0.0965, -0.2127, -0.0727],\n",
       "                      [-0.1710,  0.0734,  0.1205,  0.1769, -0.2843, -0.1038, -0.2439, -0.0100,\n",
       "                       -0.1691,  0.0951,  0.0822, -0.1922, -0.2758, -0.4680,  0.0074, -0.2827],\n",
       "                      [ 0.0449, -0.2156, -0.1127, -0.0463,  0.1164, -0.1645,  0.2439,  0.4151,\n",
       "                       -0.1010,  0.1577,  0.1378, -0.0302, -0.2121, -0.2671, -0.2714,  0.1572],\n",
       "                      [ 0.4248, -0.0443,  0.0147, -0.1607,  0.0460, -0.0926, -0.2295, -0.0855,\n",
       "                        0.1078, -0.1581,  0.3277,  0.0216,  0.0303, -0.0057, -0.1748, -0.0174],\n",
       "                      [-0.1334, -0.1421,  0.0810, -0.1113, -0.2628,  0.0803,  0.2868, -0.1761,\n",
       "                       -0.2016,  0.1141,  0.3117,  0.0816, -0.0556,  0.2063, -0.1241, -0.1388],\n",
       "                      [ 0.2869,  0.1770,  0.0305,  0.0714,  0.3557, -0.0170,  0.1523, -0.2790,\n",
       "                        0.0068, -0.2398, -0.1519, -0.2038, -0.1536,  0.2139,  0.0236,  0.2367],\n",
       "                      [-0.2710,  0.0757,  0.1339, -0.1298,  0.1152, -0.2004,  0.1648,  0.2223,\n",
       "                       -0.1191,  0.0780,  0.1817,  0.3050,  0.1723, -0.0336,  0.1381, -0.1915],\n",
       "                      [ 0.1714, -0.2360,  0.2488,  0.2630, -0.1656,  0.0781, -0.1692, -0.0655,\n",
       "                        0.0102,  0.3166,  0.1227,  0.2568, -0.2013, -0.0365, -0.4034,  0.1579],\n",
       "                      [-0.0076,  0.2635,  0.2197, -0.2958, -0.2324,  0.3315,  0.1385, -0.0721,\n",
       "                       -0.0600,  0.0078,  0.2887, -0.0371, -0.0954, -0.0293, -0.0671, -0.1387],\n",
       "                      [ 0.2361, -0.2182, -0.0876, -0.0727, -0.0722, -0.2133,  0.2646, -0.0375,\n",
       "                       -0.2644,  0.0891,  0.3351, -0.1177,  0.2717,  0.0735, -0.1511, -0.2661],\n",
       "                      [ 0.1164, -0.1169,  0.2834, -0.0564,  0.1144, -0.2015, -0.0258,  0.1484,\n",
       "                        0.1223, -0.0773,  0.2398, -0.2893,  0.2194,  0.0285,  0.0843, -0.0511],\n",
       "                      [ 0.0137, -0.0997,  0.0990, -0.1787, -0.1119,  0.0236,  0.1185, -0.1287,\n",
       "                       -0.4457, -0.4490, -0.0067,  0.1453,  0.0767,  0.1069,  0.0429, -0.3366],\n",
       "                      [ 0.0837,  0.3675,  0.4126,  0.0783, -0.0048, -0.2157,  0.2111,  0.3237,\n",
       "                       -0.2744, -0.1019,  0.0464, -0.1719, -0.1097, -0.2120,  0.0242, -0.0712],\n",
       "                      [-0.0634,  0.0312, -0.1357, -0.2869, -0.1576, -0.2320,  0.1221,  0.1167,\n",
       "                        0.0819, -0.1188,  0.3187, -0.0609,  0.2943,  0.0105, -0.1059,  0.1352],\n",
       "                      [ 0.2539, -0.1299, -0.0816,  0.0549, -0.1355,  0.2065,  0.1437, -0.2843,\n",
       "                       -0.2786,  0.1144,  0.3357, -0.1897, -0.2711, -0.0426,  0.1789,  0.0675]])),\n",
       "             ('7.bias',\n",
       "              tensor([ 0.0537,  0.1448,  0.1023,  0.1508, -0.2939,  0.2262,  0.3198,  0.1266,\n",
       "                       0.0218,  0.1919, -0.0808,  0.4161,  0.2309, -0.0171, -0.0823,  0.0724])),\n",
       "             ('9.weight',\n",
       "              tensor([1.4144, 1.4972, 1.5601, 1.5102, 1.3088, 1.4828, 1.6716, 1.1668, 1.3629,\n",
       "                      1.5544, 1.3190, 1.5321, 1.5005, 1.3753, 1.0884, 1.4851])),\n",
       "             ('9.bias',\n",
       "              tensor([ 0.1978, -0.0711,  0.0427, -0.0419, -0.0738, -0.0072, -0.0724,  0.0940,\n",
       "                      -0.0156, -0.0080, -0.0571, -0.0448,  0.0650,  0.0267, -0.0111,  0.0215])),\n",
       "             ('9.running_mean',\n",
       "              tensor([0.4534, 0.4258, 0.4961, 0.5354, 0.2014, 0.5366, 0.4951, 0.4477, 0.4048,\n",
       "                      0.4714, 0.3598, 0.5816, 0.5521, 0.4362, 0.2163, 0.5027])),\n",
       "             ('9.running_var',\n",
       "              tensor([0.2804, 0.2880, 0.3447, 0.3577, 0.1456, 0.3081, 0.4196, 0.2660, 0.3804,\n",
       "                      0.2864, 0.2223, 0.3501, 0.3007, 0.3571, 0.1706, 0.3089])),\n",
       "             ('9.num_batches_tracked', tensor(2814)),\n",
       "             ('10.weight',\n",
       "              tensor([[-2.8992e-01, -2.4979e-01,  5.0996e-01, -6.6932e-03,  7.2783e-01,\n",
       "                       -1.4746e-01, -2.4642e-03, -1.0459e-01,  2.4937e-01, -2.2147e-01,\n",
       "                        7.9725e-01,  4.3658e-01,  2.0290e-01,  3.0894e-01, -7.0370e-02,\n",
       "                        1.9257e-01],\n",
       "                      [-3.9664e-01,  8.6785e-01, -3.7091e-01, -1.0636e-01, -2.1484e-01,\n",
       "                        5.8541e-01,  6.5147e-01, -2.0283e-01, -1.2046e-01, -9.8447e-04,\n",
       "                        2.4486e-01, -3.9461e-01,  2.9907e-01, -1.6852e-01, -2.2496e-01,\n",
       "                       -4.1807e-01],\n",
       "                      [ 6.9452e-04, -4.2267e-01, -3.0365e-01, -1.2006e-01, -1.2871e-02,\n",
       "                       -4.6692e-01,  9.6429e-01, -2.2575e-01,  5.1147e-01, -3.3486e-01,\n",
       "                       -2.7470e-01,  9.8092e-02, -3.5834e-01, -2.3301e-01, -1.8131e-01,\n",
       "                       -2.6851e-02],\n",
       "                      [ 3.4587e-01,  4.9399e-01,  8.8501e-01, -2.2697e-01, -3.0666e-01,\n",
       "                       -3.2671e-01, -1.3045e-01, -2.1870e-01, -4.8927e-02, -4.4391e-01,\n",
       "                       -6.2663e-02, -4.1302e-01, -4.2324e-01, -4.2763e-02, -2.5978e-01,\n",
       "                       -2.2881e-01],\n",
       "                      [-2.9211e-01, -3.1274e-01, -1.4111e-01,  2.3795e-01,  1.0157e-01,\n",
       "                        3.9873e-01, -4.1878e-01,  2.8228e-01,  7.4069e-01,  6.0350e-01,\n",
       "                       -3.9088e-01, -1.5300e-01, -4.0297e-01, -1.3532e-01,  2.5699e-02,\n",
       "                       -2.4880e-01],\n",
       "                      [-1.2779e-01, -1.0263e-01,  3.1589e-01, -2.6464e-01, -3.9550e-01,\n",
       "                       -9.0571e-02, -1.0461e-01,  4.4961e-01, -4.9625e-01,  3.4788e-01,\n",
       "                       -8.1051e-02,  3.9250e-01,  2.0318e-01,  8.3844e-01, -6.3531e-02,\n",
       "                       -3.8807e-01],\n",
       "                      [-2.7300e-01, -1.7917e-01, -3.7516e-01, -1.4480e-01, -1.1471e-01,\n",
       "                       -4.2656e-01, -4.4350e-01, -1.0527e-01, -1.9193e-01, -2.8457e-01,\n",
       "                        1.0673e-02,  7.6216e-01, -3.6648e-01, -1.0535e-01,  5.9265e-01,\n",
       "                       -4.5531e-01],\n",
       "                      [ 8.1437e-01,  2.5763e-01, -2.9277e-01,  9.5842e-01, -1.4273e-01,\n",
       "                        3.4817e-01,  1.4144e-01,  2.8704e-01, -1.1668e-02, -4.3755e-02,\n",
       "                        4.1004e-01,  1.0726e-01, -1.0151e-02, -1.7045e-01,  1.1121e-01,\n",
       "                        4.4554e-01],\n",
       "                      [ 3.8849e-01, -2.4141e-01, -2.3958e-01, -6.4535e-01, -2.2896e-01,\n",
       "                       -1.7014e-01, -3.9477e-01,  2.1431e-01, -8.9637e-02, -5.6329e-01,\n",
       "                        2.9875e-02, -4.9044e-01,  7.5443e-01, -5.0430e-01, -1.0049e-01,\n",
       "                       -3.8392e-01],\n",
       "                      [ 2.7579e-01, -2.6030e-01,  2.9851e-01, -2.3000e-01, -6.4389e-02,\n",
       "                        5.4740e-01, -4.1277e-01, -5.6949e-02, -9.4570e-02,  7.1661e-01,\n",
       "                        3.3831e-02, -3.8557e-01, -4.3462e-01, -3.4152e-02,  4.8155e-02,\n",
       "                        7.4606e-01]])),\n",
       "             ('10.bias',\n",
       "              tensor([-0.3209, -0.1075,  0.1559,  0.2847, -0.0877,  0.3601, -0.0759, -0.0357,\n",
       "                       0.0506, -0.0190]))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"weights/mlp_mnist.pth\"\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "torch.save(mlp.state_dict(), \"weights/mlp_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.load_state_dict(torch.load(\"weights/mlp_mnist.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: also optimizers, schedulers, and metrics have a state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': tensor([[-1.9213e-05, -2.9726e-05,  3.3776e-05,  ...,  2.3047e-05,\n",
       "             1.9870e-07,  1.4562e-06],\n",
       "           [ 2.7439e-05, -1.1490e-05,  1.3584e-06,  ...,  2.0397e-05,\n",
       "             2.7295e-05,  7.6733e-06],\n",
       "           [-3.4180e-05, -1.5585e-05,  7.4561e-07,  ..., -4.4396e-06,\n",
       "             2.0146e-05,  2.3021e-05],\n",
       "           ...,\n",
       "           [-4.9157e-06, -3.0065e-05,  4.0653e-06,  ..., -3.1905e-05,\n",
       "             2.0638e-05,  2.6995e-05],\n",
       "           [ 3.2397e-05,  3.2295e-05, -1.0880e-06,  ...,  1.3289e-05,\n",
       "            -3.8246e-06, -1.9937e-05],\n",
       "           [ 6.4907e-06,  1.4357e-05, -1.0200e-05,  ...,  5.6377e-06,\n",
       "            -2.6719e-05, -7.2417e-06]])},\n",
       "  1: {'momentum_buffer': tensor([-2.7443e-05,  8.8163e-02, -8.9050e-03, -2.0647e-02, -6.6659e-03,\n",
       "            2.9545e-02, -5.4040e-02, -5.7372e-05, -1.2095e-02, -1.1882e-02,\n",
       "           -5.5319e-02, -5.5583e-02, -6.0664e-03, -1.1524e-02,  1.6978e-02,\n",
       "           -7.0066e-02])},\n",
       "  2: {'momentum_buffer': tensor([ 0.0010, -0.1076, -0.0686,  0.0689,  0.1762, -0.0762, -0.0940,  0.0010,\n",
       "           -0.0379,  0.1126, -0.0355,  0.0468,  0.0556,  0.0932,  0.0286, -0.1266])},\n",
       "  3: {'momentum_buffer': tensor([ 0.0457,  0.0487, -0.0049, -0.0114, -0.0001,  0.0482, -0.0900,  0.0465,\n",
       "            0.0010,  0.0011,  0.0143,  0.0100, -0.0077, -0.0012,  0.0176, -0.0488])},\n",
       "  4: {'momentum_buffer': tensor([[ 5.0934e-04, -6.9600e-02, -1.5076e-01, -6.8811e-02, -2.5417e-01,\n",
       "            -5.4481e-02, -1.3297e-01,  6.7995e-04, -1.0411e-01, -8.0568e-02,\n",
       "            -1.3248e-02, -1.9998e-02,  5.3209e-04, -1.2471e-01, -4.2146e-03,\n",
       "             2.7020e-02],\n",
       "           [ 4.1365e-03,  7.3751e-02, -5.9186e-02, -1.2786e-01, -2.0205e-01,\n",
       "            -1.3484e-01, -4.1682e-02,  4.3086e-03,  4.7688e-02,  5.0652e-02,\n",
       "            -5.1747e-02, -1.1426e-02,  9.5978e-02, -1.5837e-02, -6.8378e-02,\n",
       "            -3.1048e-02],\n",
       "           [ 2.8402e-03,  8.0150e-02,  3.9934e-02, -2.1718e-02, -1.9603e-01,\n",
       "            -1.9392e-01, -1.1279e-01,  3.1069e-03, -5.6839e-02,  7.9715e-02,\n",
       "             2.1502e-02,  7.8370e-04,  6.5241e-02, -8.6943e-02, -1.0723e-01,\n",
       "             5.3754e-02],\n",
       "           [ 1.2421e-03, -1.5061e-01, -4.8965e-02, -6.8124e-02, -6.9649e-02,\n",
       "            -3.3690e-02,  8.4415e-03,  1.3223e-03, -4.3457e-02,  6.0276e-03,\n",
       "            -1.0364e-01,  2.9352e-02, -1.4769e-01, -7.6398e-02,  3.4665e-02,\n",
       "             1.8351e-02],\n",
       "           [ 3.1090e-03,  1.9477e-02,  8.3814e-02,  3.9043e-02,  4.1444e-02,\n",
       "             1.1586e-01, -3.7784e-02,  3.7018e-03, -2.9421e-03, -5.4394e-02,\n",
       "            -3.7422e-02,  1.1610e-01, -1.0439e-01,  1.7114e-02, -2.3061e-02,\n",
       "            -2.4793e-02],\n",
       "           [ 7.4402e-04, -1.3047e-01,  2.6449e-03,  4.2123e-02,  1.7287e-01,\n",
       "             1.9149e-01,  1.1805e-01,  8.2047e-04, -6.3396e-02, -3.8788e-02,\n",
       "             3.6363e-02, -1.6685e-02,  1.3072e-01, -2.1923e-02,  6.4553e-02,\n",
       "             5.0022e-02],\n",
       "           [ 7.6423e-04,  2.0971e-01,  6.7239e-02,  1.5231e-01,  1.1631e-01,\n",
       "            -1.8901e-01, -2.3438e-03,  9.3199e-04,  5.9122e-02, -1.4652e-01,\n",
       "             5.7435e-02,  9.2673e-03,  9.6463e-02, -2.3859e-03,  1.3325e-01,\n",
       "            -3.0063e-02],\n",
       "           [-7.3704e-03,  1.2427e-01,  1.4925e-01,  2.9963e-02, -1.2486e-01,\n",
       "            -6.9273e-02, -1.0938e-01, -7.7058e-03,  5.4274e-02,  1.6219e-01,\n",
       "            -4.1041e-02,  8.4166e-02, -2.8621e-02, -6.8042e-02, -1.8387e-01,\n",
       "             1.9549e-02],\n",
       "           [ 1.0819e-03,  5.7467e-02,  6.2175e-02,  2.1243e-02, -1.3205e-01,\n",
       "            -2.5579e-02, -1.4788e-01,  1.1690e-03, -1.4566e-01, -1.4187e-01,\n",
       "             5.6684e-02,  1.1348e-01, -1.9169e-01, -2.3148e-01, -9.1954e-02,\n",
       "             2.0758e-02],\n",
       "           [-1.8154e-03,  4.8488e-02,  8.4046e-02, -2.1781e-02,  1.5033e-01,\n",
       "             8.6880e-02, -4.1555e-02, -1.8154e-03, -3.2558e-02, -8.9896e-02,\n",
       "            -2.4718e-02,  8.6053e-03,  4.8129e-02, -2.2285e-01,  1.8744e-01,\n",
       "             4.0246e-03],\n",
       "           [ 7.8605e-04,  7.2703e-02,  3.4612e-04, -1.1636e-02, -1.2544e-01,\n",
       "            -1.2723e-01, -2.7170e-02,  5.7026e-04, -5.0642e-02, -1.0126e-01,\n",
       "             9.2461e-02, -1.0288e-02,  5.9397e-02,  2.3271e-02,  8.1772e-02,\n",
       "            -1.0827e-02],\n",
       "           [ 1.7261e-03,  2.4388e-01,  2.9723e-02,  2.0914e-01, -3.3945e-02,\n",
       "             1.0921e-01, -7.9189e-02,  1.7806e-03,  1.0834e-01,  1.2351e-01,\n",
       "            -1.4767e-02,  1.6348e-02,  7.2819e-02,  9.6887e-02, -1.9154e-01,\n",
       "             1.6292e-01],\n",
       "           [-2.5748e-03,  4.1908e-02, -2.4094e-02,  2.7995e-01,  1.8794e-01,\n",
       "             2.0043e-01, -6.9367e-02, -2.4399e-03,  1.2301e-02, -5.2886e-03,\n",
       "            -2.7345e-02,  6.2295e-02,  1.1530e-01, -4.1215e-03, -5.4154e-02,\n",
       "            -2.1587e-01],\n",
       "           [ 1.7059e-03,  1.8985e-01, -4.0563e-02,  3.1825e-02, -1.8057e-01,\n",
       "            -2.3788e-01, -7.4080e-02,  1.3681e-03, -1.3263e-02, -4.2810e-03,\n",
       "             5.0404e-02, -2.9751e-02,  3.6608e-02,  1.2960e-01, -7.0651e-02,\n",
       "            -4.0743e-02],\n",
       "           [ 3.9652e-03, -1.5900e-01,  1.3956e-02, -6.2143e-02,  1.1996e-01,\n",
       "             1.9269e-01,  2.9078e-01,  3.8684e-03, -2.1226e-02, -1.2347e-01,\n",
       "             1.4435e-01, -5.7041e-02, -2.1210e-01,  3.0130e-01,  1.4343e-01,\n",
       "             2.0515e-02],\n",
       "           [-4.5141e-03, -5.3852e-02,  7.1234e-02, -1.7412e-02,  1.7818e-01,\n",
       "             1.3671e-01,  7.6438e-02, -4.8247e-03, -2.9776e-02, -1.5211e-01,\n",
       "             4.8804e-02,  2.8640e-04, -1.5733e-01,  8.1508e-02,  4.2272e-03,\n",
       "             7.4248e-02]])},\n",
       "  5: {'momentum_buffer': tensor([ 0.0108,  0.0735,  0.0506,  0.0191,  0.0602,  0.0127,  0.0150, -0.1284,\n",
       "            0.0199, -0.0318,  0.0138,  0.0282, -0.0434,  0.0273,  0.0674, -0.0836])},\n",
       "  6: {'momentum_buffer': tensor([-0.0730,  0.0416,  0.0537,  0.0078,  0.0161,  0.1041, -0.1222, -0.0430,\n",
       "           -0.0331,  0.0116,  0.0120, -0.0691,  0.0743, -0.0231, -0.0278,  0.1089])},\n",
       "  7: {'momentum_buffer': tensor([ 0.0142,  0.0149,  0.0137,  0.0300, -0.0064, -0.0262, -0.0295,  0.0350,\n",
       "            0.0336,  0.0215,  0.0025, -0.0189, -0.0145, -0.0418, -0.0178, -0.0308])},\n",
       "  8: {'momentum_buffer': tensor([[ 2.6751e-02,  7.7374e-03, -7.0705e-02, -2.4826e-02, -1.7986e-01,\n",
       "             2.0569e-01, -1.8420e-02, -9.4891e-02,  7.4840e-02,  1.3836e-01,\n",
       "            -4.4450e-02,  1.9360e-02,  8.2851e-02,  4.1214e-02,  7.1036e-02,\n",
       "             8.9248e-02],\n",
       "           [ 4.3149e-02,  5.7825e-02,  1.1752e-02, -1.3728e-03,  3.3953e-02,\n",
       "            -6.9307e-02, -4.8850e-02, -2.3700e-02, -5.0204e-02, -4.8135e-02,\n",
       "             1.6278e-02,  1.7379e-02, -6.8351e-02, -1.7395e-01,  1.0512e-01,\n",
       "             5.6655e-02],\n",
       "           [-5.0044e-03, -3.9368e-02,  3.1880e-02, -2.1751e-02,  6.5571e-02,\n",
       "             6.7253e-02,  1.5678e-01,  6.0342e-02, -2.1082e-04, -2.0504e-02,\n",
       "             1.1181e-01,  2.7485e-02, -1.3777e-01, -4.3305e-02, -7.8344e-02,\n",
       "            -5.1146e-03],\n",
       "           [ 9.1596e-02, -1.4343e-02, -1.1136e-01,  5.4024e-02,  1.6651e-01,\n",
       "            -1.9532e-01, -8.9667e-02, -2.3779e-02,  4.2517e-02, -1.7617e-01,\n",
       "            -5.3999e-02, -1.1288e-01,  3.2928e-02,  4.1113e-02,  8.1387e-02,\n",
       "             2.3867e-01],\n",
       "           [-2.9067e-02, -5.3793e-02,  1.6930e-02, -1.9645e-02,  7.3626e-02,\n",
       "            -5.9053e-02, -1.4603e-03,  1.7756e-02, -1.2978e-01, -8.1827e-02,\n",
       "             2.7076e-02, -3.4526e-02, -3.0295e-02, -3.8602e-03,  2.8729e-02,\n",
       "            -1.1305e-01],\n",
       "           [-2.9953e-03, -2.4498e-02, -7.7063e-02, -3.9379e-03, -2.2817e-02,\n",
       "             4.3596e-02, -8.4487e-02,  3.3926e-03, -1.0369e-02,  9.3432e-02,\n",
       "             5.7524e-02,  8.7767e-02, -3.6645e-02, -2.4494e-02,  2.8957e-02,\n",
       "             2.3373e-02],\n",
       "           [-4.0535e-02,  3.3628e-02,  4.5873e-03, -1.1410e-01,  2.5211e-02,\n",
       "            -3.3115e-02,  4.1304e-02,  1.0285e-01,  1.8745e-01, -5.5918e-02,\n",
       "             3.4519e-02,  5.9254e-02, -2.7246e-02,  5.6460e-02, -1.8831e-01,\n",
       "             1.1410e-01],\n",
       "           [ 3.9705e-02,  3.6687e-02,  1.6054e-02,  2.0273e-02,  4.7764e-02,\n",
       "            -1.0988e-01, -7.8741e-02,  2.0547e-02, -4.7436e-03, -5.0051e-02,\n",
       "            -9.6389e-02, -3.5898e-02,  7.6486e-02,  4.8527e-02,  9.0827e-02,\n",
       "             3.4038e-03],\n",
       "           [ 1.1925e-01, -3.3674e-02, -3.6173e-03,  1.0441e-01,  3.1606e-02,\n",
       "            -1.5135e-01, -7.0762e-02,  2.0700e-02,  3.1835e-02, -9.1632e-02,\n",
       "            -7.7130e-02, -6.9238e-02,  5.7539e-02,  7.5440e-02, -4.0624e-02,\n",
       "             3.8714e-02],\n",
       "           [-2.0706e-02, -1.6970e-02, -5.9877e-02, -1.6485e-02,  2.1386e-02,\n",
       "            -1.0580e-02, -1.9180e-02,  1.8146e-02, -6.7234e-02,  1.3119e-01,\n",
       "             2.5768e-02,  7.0569e-02, -9.3621e-02, -7.7688e-03, -1.0948e-02,\n",
       "            -4.7696e-02],\n",
       "           [ 5.1005e-03, -8.9325e-02, -4.2977e-02, -8.9141e-03,  6.9319e-02,\n",
       "            -5.8269e-03, -9.3080e-02, -9.9519e-03, -7.3268e-02, -1.2328e-02,\n",
       "             1.2305e-01,  3.2778e-02, -8.7234e-02, -5.6334e-02,  5.5591e-02,\n",
       "             4.8462e-02],\n",
       "           [-5.6566e-02,  5.8896e-03,  8.2917e-02,  4.9603e-02,  1.0459e-01,\n",
       "            -2.0747e-02,  3.5593e-02, -3.8448e-02, -6.3831e-02, -5.5616e-02,\n",
       "            -2.3691e-02, -1.9502e-02, -1.2995e-01,  9.4204e-02,  6.7558e-03,\n",
       "            -5.0152e-02],\n",
       "           [ 5.3014e-02, -8.5837e-02,  6.2360e-03,  4.5836e-02,  4.4660e-03,\n",
       "            -4.8912e-02, -1.5064e-01,  1.0351e-01,  2.1703e-02, -1.9199e-02,\n",
       "            -6.6746e-02,  4.1072e-02,  2.8069e-01, -4.3676e-02,  9.6554e-02,\n",
       "            -4.3150e-02],\n",
       "           [-1.4544e-02, -4.8277e-02,  6.0894e-04,  2.8907e-02,  3.0521e-02,\n",
       "            -3.3711e-02, -2.2861e-04,  2.5457e-02,  1.3046e-03, -4.5532e-03,\n",
       "            -3.6235e-02,  6.5474e-02, -1.1016e-01, -1.6227e-02, -3.5278e-02,\n",
       "            -3.9079e-03],\n",
       "           [-4.7113e-02,  2.4369e-02, -3.3830e-02, -8.1087e-03,  3.3585e-02,\n",
       "             3.3424e-02,  2.3775e-02, -3.2441e-02, -1.7213e-04,  3.3171e-02,\n",
       "             5.2182e-03, -1.0948e-02, -1.2656e-02,  1.6480e-02, -2.1713e-02,\n",
       "             3.1431e-02],\n",
       "           [-2.0622e-01,  7.2834e-02, -1.2295e-01, -1.8055e-01, -1.1489e-01,\n",
       "             1.9627e-01,  7.5152e-02, -4.1215e-02,  2.9788e-02,  2.4198e-01,\n",
       "            -9.5692e-02,  9.3777e-02, -9.5008e-02,  7.2548e-02, -5.7129e-02,\n",
       "             4.7650e-02]])},\n",
       "  9: {'momentum_buffer': tensor([-0.0501,  0.0064,  0.0581,  0.0137,  0.0127, -0.0453, -0.0282, -0.0148,\n",
       "           -0.0073, -0.0046,  0.0374,  0.0090, -0.0403,  0.0210, -0.0283, -0.0234])},\n",
       "  10: {'momentum_buffer': tensor([ 0.0505, -0.0897,  0.0048, -0.0497,  0.0080, -0.0627, -0.0331, -0.0180,\n",
       "           -0.0645, -0.0385, -0.0340, -0.0406, -0.0099,  0.0394, -0.0548,  0.0989])},\n",
       "  11: {'momentum_buffer': tensor([ 0.0523, -0.0473,  0.0504, -0.0447, -0.0091,  0.0307, -0.0503,  0.0100,\n",
       "           -0.0780,  0.0654,  0.0290, -0.0080,  0.0096,  0.0446,  0.0088,  0.1067])},\n",
       "  12: {'momentum_buffer': tensor([[-1.5994e-02,  1.5096e-02,  3.6954e-02,  2.9077e-03,  7.1265e-04,\n",
       "            -1.3264e-02,  4.4931e-03,  8.6609e-03, -7.7809e-02, -4.8495e-02,\n",
       "             1.6923e-02,  2.5841e-02,  3.3793e-02,  2.2864e-02, -6.1793e-03,\n",
       "             1.2348e-02],\n",
       "           [-1.1185e-02, -6.3909e-02,  3.3479e-02,  5.2421e-02,  2.8286e-02,\n",
       "            -7.6782e-02, -3.7112e-02,  3.0907e-02,  3.2804e-02, -5.0886e-02,\n",
       "            -5.7356e-03,  3.0363e-02, -2.3053e-02,  2.0245e-02,  2.0970e-02,\n",
       "            -8.9893e-03],\n",
       "           [-1.2043e-01,  6.0174e-02, -1.3056e-02, -3.3995e-03,  6.4945e-03,\n",
       "             6.4733e-02, -4.6298e-02,  3.6740e-03, -2.1938e-03,  4.0876e-02,\n",
       "            -1.8657e-03, -2.3710e-02, -9.0052e-03,  7.7263e-03,  3.7309e-02,\n",
       "            -6.1182e-02],\n",
       "           [-5.1425e-02, -3.5572e-02, -1.4331e-02,  4.4544e-02,  3.7934e-02,\n",
       "             3.9863e-02, -2.3728e-02,  1.5503e-02,  3.7332e-02,  7.2019e-02,\n",
       "             2.7939e-02,  4.7814e-02,  3.3865e-02,  3.2600e-02,  1.1628e-02,\n",
       "             6.1956e-02],\n",
       "           [ 1.0942e-02,  6.8193e-02,  3.3192e-03, -5.9555e-02,  5.8841e-02,\n",
       "            -1.5079e-01,  9.6907e-02,  5.0663e-03, -7.4249e-02, -1.5093e-01,\n",
       "             6.4758e-02,  1.0223e-01,  6.6859e-02,  7.0379e-02,  3.0625e-02,\n",
       "            -1.1403e-01],\n",
       "           [-2.1065e-02, -1.4392e-04, -8.6323e-03,  5.0998e-03, -2.7604e-02,\n",
       "            -2.6572e-02, -2.0701e-02,  2.1613e-02, -7.0326e-03, -4.3731e-02,\n",
       "            -4.4493e-02, -1.9989e-02, -1.0409e-02,  2.7652e-02, -1.6672e-02,\n",
       "            -7.2716e-02],\n",
       "           [ 2.5238e-02,  3.4968e-02,  2.4053e-02, -6.4226e-03, -2.4225e-02,\n",
       "             4.6075e-02,  3.4326e-02, -4.7581e-03,  2.5941e-02,  6.9758e-02,\n",
       "             4.3726e-03, -5.2821e-02,  1.8204e-02,  2.2445e-02, -7.0457e-02,\n",
       "             5.6765e-02],\n",
       "           [ 7.3970e-02, -4.2027e-02, -3.4949e-02, -6.4511e-02, -2.3344e-02,\n",
       "            -6.4583e-02,  1.1560e-01, -6.3247e-02,  2.0361e-02, -3.2369e-02,\n",
       "            -9.0543e-02, -2.8287e-02, -6.3326e-02, -6.7817e-02, -1.3212e-02,\n",
       "             2.0693e-02],\n",
       "           [ 5.9428e-02, -3.1362e-02, -3.9235e-02, -5.8586e-02, -5.4643e-03,\n",
       "             1.0157e-02, -2.2139e-02, -1.4472e-02, -1.3991e-02,  3.3663e-03,\n",
       "             4.8594e-02,  4.2189e-02,  8.9585e-03, -5.6682e-02,  3.5305e-02,\n",
       "            -3.2793e-02],\n",
       "           [ 5.0970e-02, -5.5669e-03,  1.2685e-02,  8.6954e-02, -5.2282e-02,\n",
       "             1.7141e-01, -1.0150e-01, -2.6284e-03,  5.9285e-02,  1.4017e-01,\n",
       "            -1.9231e-02, -1.2367e-01, -5.6423e-02, -7.9659e-02, -2.9438e-02,\n",
       "             1.3718e-01]])},\n",
       "  13: {'momentum_buffer': tensor([ 0.0048, -0.0315, -0.0158, -0.0286, -0.0675,  0.0367, -0.0142, -0.0018,\n",
       "            0.0097,  0.1084])}},\n",
       " 'param_groups': [{'lr': 1e-05,\n",
       "   'momentum': 0.9,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0.0001,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'initial_lr': 0.01,\n",
       "   'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 1,\n",
       " 'gamma': 0.1,\n",
       " 'base_lrs': [0.01],\n",
       " 'last_epoch': 3,\n",
       " 'verbose': False,\n",
       " '_step_count': 4,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [1e-05]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_correct': tensor(9451.), 'num_total': tensor(10000.)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_counter.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving checkpoints\n",
    "\n",
    "You can also save checkpoints during training. This is useful in case the training is interrupted and you want to resume from the last checkpoint.\n",
    "\n",
    "The checkpoint should contain all the information needed to resume training:\n",
    "- The epoch number\n",
    "  - In case you're saving the checkpoint mid-epoch, you must save the iteration number as well, and also the partial metrics\n",
    "- The model's state_dict\n",
    "- The optimizer's state_dict\n",
    "- If you're using a learning rate scheduler, you should save its state_dict as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "\n",
    "We can do transfer learning by loading a pretrained model and changing the last layer to match the number of classes in our dataset.\n",
    "\n",
    "`timm` and `torchvision` provide a number of pretrained models that can be used for transfer learning.\n",
    "\n",
    "We can create the models by passing the `pretrained=True` argument and the num_classes argument to match the number of classes in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained = timm.create_model(\"resnet18\", pretrained=True, num_classes=10)\n",
    "\n",
    "model_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = timm.create_model(\"resnet18\", pretrained=False, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We additionaly need to modify our dataset since ResNet18 is a CNN and expects a 3-channel input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train.transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomAffine(degrees=10, scale=(0.9, 1.1)),\n",
    "    T.Lambda(lambda x: x.repeat(3, 1, 1)), # repeat the single channel 3 times to get 3 channels\n",
    "    \n",
    "])\n",
    "\n",
    "mnist_test.transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 938/938 [03:54<00:00,  4.00it/s, accuracy=0.906, loss=0.315]\n",
      "Epoch 2/2:  54%|█████▍    | 505/938 [02:12<01:53,  3.81it/s, accuracy=0.97, loss=0.0995] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer_pretrained \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model_pretrained\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      4\u001b[0m scheduler_pretrained \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_pretrained, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_pretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_pretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m optimizer_scratch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model_scratch\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      9\u001b[0m scheduler_scratch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_scratch, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[98], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, trainloader, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(predictions, labels)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m accuracy_counter\u001b[38;5;241m.\u001b[39mupdate(predictions, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "optimizer_pretrained = torch.optim.SGD(model_pretrained.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler_pretrained = torch.optim.lr_scheduler.StepLR(optimizer_pretrained, step_size=1, gamma=0.1)\n",
    "\n",
    "train(model_pretrained, optimizer_pretrained, scheduler_pretrained, trainloader, num_epochs)\n",
    "\n",
    "optimizer_scratch = torch.optim.SGD(model_scratch.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler_scratch = torch.optim.lr_scheduler.StepLR(optimizer_scratch, step_size=1, gamma=0.1)\n",
    "\n",
    "train(model_scratch, optimizer_scratch, scheduler_scratch, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally freeze the hidden layers of the pretrained model by setting `requires_grad=False` for the parameters of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model_pretrained.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# you can proceed to retrain the model. Note: you have to reload the parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using acceleration\n",
    "\n",
    "We can use the GPU to accelerate the training process.\n",
    "\n",
    "We can move the model and the data to the GPU and CPU using the `to` method.\n",
    "\n",
    "`to` accepts a device argument which can be either `cuda` or `cpu`.\n",
    "\n",
    "In case of multiple GPUs available, we can force the usage of a specific GPU by specifying the device number (e.g., `cuda:0` for first GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA not available"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.to(\"cuda\")\n",
    "else:\n",
    "    raise RuntimeError(\"CUDA not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training/evaluating a model on CUDA, we need to shift to the GPU the following:\n",
    "- The model (`model.to(device)`)\n",
    "- The data (`data = data.to(device)`)\n",
    "- The labels (`labels = labels.to(device)`)\n",
    "\n",
    "In addition, for single-node multi-GPU training, we can use `torch.nn.DataParallel` to parallelize the training process.\n",
    "\n",
    "We can wrap the model using `torch.nn.DataParallel(model)` and PyTorch will automatically distribute the batches to the GPUs.\n",
    "\n",
    "```python\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "```\n",
    "\n",
    "#### Using mixed precision\n",
    "\n",
    "We can use mixed precision (`FLOAT16/FLOAT32`) training to speed up the training process.\n",
    "\n",
    "We can use the `torch.cuda.amp` module to enable mixed precision training.\n",
    "\n",
    "We can use the `torch.cuda.amp.autocast` context manager to automatically cast the inputs to the model to `FLOAT16`.\n",
    "\n",
    "We can use the `torch.cuda.amp.GradScaler` to scale the loss to avoid underflow/overflow issues.\n",
    "\n",
    "```python\n",
    "\n",
    "def train_mixed_precision(model, optimizer, scheduler, trainloader, epochs, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        accuracy_counter = metrics.MulticlassAccuracy().to(device)\n",
    "        loss_counter = metrics.Mean().to(device)\n",
    "\n",
    "        progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for data, labels in progress_bar:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictions = model(data)\n",
    "                loss = nn.functional.cross_entropy(predictions, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            accuracy_counter.update(predictions, labels)\n",
    "            loss_counter.update(loss, weight=data.size(0))\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss=loss_counter.compute().item(),\n",
    "                accuracy=accuracy_counter.compute().item()\n",
    "            )\n",
    "        scheduler.step()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
